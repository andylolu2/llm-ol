{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from llm_ol.dataset import data_model\n",
    "from llm_ol.eval.graph_metrics import random_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# graph_file = \"out/experiments/prompting/v4/graph.json\"\n",
    "# graph_file = \"out/experiments/finetune/v6/16500/graph.json\"\n",
    "graph_file = \"out/experiments/rebel/v1/test/graph.json\"\n",
    "G = data_model.load_graph(graph_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def dist_hist(G):\n",
    "    dist_from_root = nx.single_source_shortest_path_length(G, G.graph[\"root\"])\n",
    "    ax = sns.histplot(list(dist_from_root.values()), discrete=True)\n",
    "    _ = ax.set(yscale=\"log\")\n",
    "\n",
    "\n",
    "dist_hist(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "weights = nx.get_edge_attributes(G, \"weight\")\n",
    "\n",
    "ax = sns.histplot(list(weights.values()), log_scale=True, bins=20)\n",
    "_ = ax.set(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def inspect_node(node):\n",
    "    edges = []\n",
    "    weights = []\n",
    "    for u, v, data in G.out_edges(node, data=True):\n",
    "        edges.append((u, v))\n",
    "        weights.append(data[\"weight\"])\n",
    "    weights = np.array(weights)\n",
    "    idx = np.argsort(weights)[::-1]\n",
    "    return [edges[i] for i in idx], weights[idx]\n",
    "\n",
    "\n",
    "def prune_edges(node, percentile: float):\n",
    "    edges, weights = inspect_node(node)\n",
    "    p = weights / weights.sum()\n",
    "    idx = np.argwhere(p.cumsum() - p > percentile).flatten()\n",
    "    return [edges[i] for i in idx]\n",
    "\n",
    "\n",
    "# node = G.graph[\"root\"]\n",
    "node = random.choice(list(G.nodes))\n",
    "while len(G[node]) == 0:\n",
    "    node = random.choice(list(G.nodes))\n",
    "print(len(G[node]))\n",
    "\n",
    "print(G.nodes(\"title\")[node])\n",
    "edges, weights = inspect_node(node)\n",
    "to_remove = prune_edges(node, 0.9)\n",
    "print([(edge, weight) for edge, weight in zip(edges, weights) if edge not in to_remove])\n",
    "print([(edge, weight) for edge, weight in zip(edges, weights) if edge in to_remove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "component_sizes = [len(c) for c in nx.weakly_connected_components(G)]\n",
    "\n",
    "ax = sns.histplot(component_sizes)\n",
    "ax.set(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_to_remove = set()\n",
    "for node in G.nodes:\n",
    "    to_remove = prune_edges(node, 0.99)\n",
    "    edges_to_remove.update(to_remove)\n",
    "for u, v, w in G.edges(data=\"weight\"):\n",
    "    if G.has_edge(v, u):\n",
    "        w_ = G.edges[v, u][\"weight\"]\n",
    "        if w_ > w:\n",
    "            print(f\"Removing {u} -> {v} ({w} < {w_})\")\n",
    "            edges_to_remove.add((u, v))\n",
    "        else:\n",
    "            print(f\"Removing {v} -> {u} ({w_} < {w})\")\n",
    "            edges_to_remove.add((v, u))\n",
    "\n",
    "G_pruned = G.copy()\n",
    "G_pruned.remove_edges_from(edges_to_remove)\n",
    "G_pruned = G_pruned.subgraph(\n",
    "    nx.descendants(G_pruned, G_pruned.graph[\"root\"]) | {G_pruned.graph[\"root\"]}\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Removed {G.number_of_nodes() - G_pruned.number_of_nodes()}/{G.number_of_nodes()} nodes\"\n",
    ")\n",
    "print(f\"Removed {len(edges_to_remove)}/{G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_hist(G_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_sub = random_subgraph(G, 1)\n",
    "G_sub = nx.ego_graph(G_pruned, G.graph[\"root\"], radius=1)\n",
    "A = nx.nx_agraph.to_agraph(G_sub)\n",
    "A.layout(\"fdp\")\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"out/data/wikipedia/v2/train_test_split/train_graph.json\"\n",
    "G_train = data_model.load_graph(train_file)\n",
    "dist_from_root_train = nx.single_source_shortest_path_length(\n",
    "    G_train, G_train.graph[\"root\"]\n",
    ")\n",
    "dist_from_root_train = {\n",
    "    G_train.nodes[n][\"title\"]: d for n, d in dist_from_root_train.items()\n",
    "}\n",
    "\n",
    "test_file = \"out/data/wikipedia/v2/train_test_split/test_graph.json\"\n",
    "G_test = data_model.load_graph(test_file)\n",
    "dist_from_root_test = nx.single_source_shortest_path_length(\n",
    "    G_test, G_test.graph[\"root\"]\n",
    ")\n",
    "dist_from_root_test = {\n",
    "    G_test.nodes[n][\"title\"]: d for n, d in dist_from_root_test.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, weights = inspect_node(G.graph[\"root\"])\n",
    "nodes = [v for u, v in edges]\n",
    "train_nodes = {n for n, d in dist_from_root_train.items() if d == 1}\n",
    "test_nodes = {n for n, d in dist_from_root_test.items() if d == 1}\n",
    "\n",
    "missing_nodes = (train_nodes | test_nodes) - set(nodes)\n",
    "nodes += list(missing_nodes)\n",
    "weights = np.concatenate([weights, np.zeros(len(missing_nodes))])\n",
    "in_train = [n in train_nodes for n in nodes]\n",
    "in_test = [n in test_nodes for n in nodes]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"node\": nodes, \"weight\": weights, \"in_train\": in_train, \"in_test\": in_test}\n",
    ")\n",
    "# df[\"missing\"] = df.weight == 0\n",
    "\n",
    "# print lowest weight nodes in train and test\n",
    "display(df[df.in_train].sort_values(\"weight\").head(20))\n",
    "display(df[df.in_test].sort_values(\"weight\").head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_top_level = {n for n, d in dist_from_root_test.items() if d == 1}\n",
    "top_level = {\n",
    "    n\n",
    "    for n, d in nx.single_source_shortest_path_length(G, G.graph[\"root\"]).items()\n",
    "    if d == 1\n",
    "}\n",
    "print(test_top_level - top_level)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-ol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
