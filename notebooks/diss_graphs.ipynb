{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import graph_tool\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import dotenv\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "from llm_ol.utils import load_runs, sized_subplots\n",
    "from llm_ol.dataset import data_model\n",
    "from llm_ol.eval.graph_metrics import (\n",
    "    edge_prec_recall_f1,\n",
    "    embed_graph,\n",
    "    from_networkx,\n",
    "    SGConv,\n",
    "    Batch,\n",
    "    device,\n",
    "    cosine_sim,\n",
    "    linear_sum_assignment,\n",
    "    batch,\n",
    ")\n",
    "from llm_ol.experiments.post_processing import post_process, PostProcessHP\n",
    "from metadata import query\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "fig_dir = Path(\"out\", \"graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "run = load_runs(\"v2-data-eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data = [{\"Loss\": 2.136, \"Step\": 0, \"Split\": \"Eval\"}]\n",
    "for m in run.scan_history(keys=[\"eval/loss\", \"train/global_step\"], page_size=10000):\n",
    "    data.append(\n",
    "        {\"Loss\": m[\"eval/loss\"], \"Step\": m[\"train/global_step\"], \"Split\": \"Eval\"}\n",
    "    )\n",
    "for m in run.scan_history(keys=[\"train/loss\", \"train/global_step\"], page_size=10000):\n",
    "    data.append(\n",
    "        {\"Loss\": m[\"train/loss\"], \"Step\": m[\"train/global_step\"], \"Split\": \"Train\"}\n",
    "    )\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df[\"Epoch\"] = df[\"Step\"] / 8500\n",
    "fig, axs = sized_subplots(ax_size=(5, 3))\n",
    "sns.lineplot(\n",
    "    data=df.query(\"Epoch <= 1\"),\n",
    "    x=\"Epoch\",\n",
    "    y=\"Loss\",\n",
    "    hue=\"Split\",\n",
    "    ax=axs[0, 0],\n",
    "    marker=\"\",\n",
    "    hue_order=[\"Train\", \"Eval\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hearst naive precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "G_true = data_model.load_graph(\"out/data/wikipedia/v2/train_eval_split/test_graph.json\")\n",
    "G_pred = data_model.load_graph(\"out/experiments/hearst/v2/eval/graph.json\")\n",
    "assert G_true.number_of_nodes() == G_pred.number_of_nodes()\n",
    "prec, recall, f1 = edge_prec_recall_f1(G_pred, G_true)\n",
    "print(f\"Precision: {prec}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REBEL example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model_id = \"Babelscape/rebel-large\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"A chihuahua is a kind of dog.\", return_tensors=\"pt\")\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    length_penalty=0.0,\n",
    "    max_length=256,\n",
    "    min_length=12,\n",
    "    no_repeat_ngram_size=0,\n",
    "    num_beams=4,  # Recommend 4 but 2 is faster\n",
    ")\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "exp = query(exp=\"finetune\", transfer=True, reweighted=True, dataset=\"arxiv/v2\")\n",
    "G_true = data_model.load_graph(exp.test_ground_truth)\n",
    "G_pred = data_model.load_graph(exp.test_output)\n",
    "G_pred, _ = post_process(G_pred, PostProcessHP(**exp.best_hp(\"edge_soft_f1\")))\n",
    "\n",
    "nodes_true = [G_true.nodes[n][\"title\"] for n in G_true.nodes]\n",
    "nodes_pred = [G_pred.nodes[n][\"title\"] for n in G_pred.nodes]\n",
    "edges_true = [\n",
    "    (G_true.nodes[u][\"title\"], G_true.nodes[v][\"title\"]) for u, v in G_true.edges\n",
    "]\n",
    "edges_pred = [\n",
    "    (G_pred.nodes[u][\"title\"], G_pred.nodes[v][\"title\"]) for u, v in G_pred.edges\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def graph_fuzzy_match(\n",
    "    G1: nx.DiGraph,\n",
    "    G2: nx.DiGraph,\n",
    "    n_iters: int = 3,\n",
    "    embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    direction: str = \"forward\",\n",
    ") -> tuple[float, float, float] | tuple[None, None, None]:\n",
    "    if len(G1) == 0 or len(G2) == 0:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    # Skip computation if too slow. Time complexity is O(n^2 m)\n",
    "    n, m = min(len(G1), len(G2)), max(len(G1), len(G2))\n",
    "    if (n**2 * m) > 20000**3:\n",
    "        return None, None, None\n",
    "\n",
    "    G1 = embed_graph(G1, embedding_model=embedding_model)\n",
    "    G2 = embed_graph(G2, embedding_model=embedding_model)\n",
    "\n",
    "    if direction == \"forward\":\n",
    "        pass\n",
    "    elif direction == \"reverse\":\n",
    "        G1 = G1.reverse(copy=False)\n",
    "        G2 = G2.reverse(copy=False)\n",
    "    elif direction == \"undirected\":\n",
    "        G1 = G1.to_undirected(as_view=True).to_directed(as_view=True)\n",
    "        G2 = G2.to_undirected(as_view=True).to_directed(as_view=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid direction {direction}\")\n",
    "\n",
    "    def nx_to_vec(G: nx.Graph, n_iters) -> torch.Tensor:\n",
    "        \"\"\"Compute a graph embedding of shape (n_nodes embed_dim).\n",
    "\n",
    "        Uses a GCN with identity weights to compute the embedding.\n",
    "        \"\"\"\n",
    "\n",
    "        # Delete all node and edge attributes except for the embedding\n",
    "        # Otherwise PyG might complain \"Not all nodes/edges contain the same attributes\"\n",
    "        G = G.copy()\n",
    "        for _, _, d in G.edges(data=True):\n",
    "            d.clear()\n",
    "        for _, d in G.nodes(data=True):\n",
    "            for k in list(d.keys()):\n",
    "                if k != \"embed\":\n",
    "                    del d[k]\n",
    "        pyg_G = from_networkx(G, group_node_attrs=[\"embed\"])\n",
    "\n",
    "        embed_dim = pyg_G.x.shape[1]\n",
    "        conv = SGConv(embed_dim, embed_dim, K=n_iters, bias=False).to(device)\n",
    "        conv.lin.weight.data = torch.eye(embed_dim, device=conv.lin.weight.device)\n",
    "\n",
    "        pyg_batch = Batch.from_data_list([pyg_G])\n",
    "        x, edge_index = pyg_batch.x, pyg_batch.edge_index  # type: ignore\n",
    "        x, edge_index = x.to(device), edge_index.to(device)\n",
    "        x = conv(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # Compute embeddings\n",
    "    x1 = nx_to_vec(G1, n_iters)\n",
    "    x2 = nx_to_vec(G2, n_iters)\n",
    "\n",
    "    # Cosine similarity matrix\n",
    "    sim = cosine_sim(x1, x2, dim=-1).cpu().numpy()\n",
    "\n",
    "    # soft precision, recall, f1\n",
    "    row_ind, col_ind = linear_sum_assignment(sim, maximize=True)\n",
    "    return sim, row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "sim, row_ind, col_ind = graph_fuzzy_match(\n",
    "    G_true, G_pred, n_iters=2, direction=\"forward\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def display_graph(G: nx.Graph, layout: str = \"dot\", **kwargs):\n",
    "    # relabel_map = {}\n",
    "    # for n, data in G.nodes(data=True):\n",
    "    #     relabel_map[n] = data.get(\"title\", n)\n",
    "    # G = nx.relabel_nodes(G, relabel_map)\n",
    "    for n, data in G.nodes(data=True):\n",
    "        title = data.get(\"title\", n)\n",
    "        # data.clear()\n",
    "        data[\"label\"] = title\n",
    "    # for u, v, data in G.edges(data=True):\n",
    "    #     data.clear()\n",
    "\n",
    "    A = nx.nx_agraph.to_agraph(G)\n",
    "    A.node_attr.update(fontname=\"Helvetica\", fontsize=10, shape=\"plaintext\")\n",
    "    A.graph_attr.update(ratio=\"compress\")\n",
    "    A.edge_attr.update(arrowsize=0.5)\n",
    "    for k, v in kwargs.items():\n",
    "        if k.startswith(\"G\"):\n",
    "            A.graph_attr[k[1:]] = v\n",
    "        elif k.startswith(\"N\"):\n",
    "            A.node_attr[k[1:]] = v\n",
    "        elif k.startswith(\"E\"):\n",
    "            A.edge_attr[k[1:]] = v\n",
    "    A.layout(layout)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def rgba_to_hex(r, g, b, a):\n",
    "    return f\"#{r:02x}{g:02x}{b:02x}{a:02x}\"\n",
    "\n",
    "\n",
    "G_both = nx.DiGraph()\n",
    "for n in G_true.nodes:\n",
    "    G_both.add_node(f\"{n}1\", title=G_true.nodes[n][\"title\"])\n",
    "for n in G_pred.nodes:\n",
    "    G_both.add_node(f\"{n}2\", title=G_pred.nodes[n][\"title\"], fontcolor=\"deepskyblue4\")\n",
    "for u, v in G_true.edges:\n",
    "    G_both.add_edge(f\"{u}1\", f\"{v}1\")\n",
    "for u, v in G_pred.edges:\n",
    "    G_both.add_edge(f\"{u}2\", f\"{v}2\", color=\"deepskyblue4\")\n",
    "\n",
    "for i, j in zip(row_ind, col_ind):\n",
    "    u, v = list(G_true.nodes)[i], list(G_pred.nodes)[j]\n",
    "    s = sim[i, j] ** 4\n",
    "    G_both.add_edge(\n",
    "        f\"{u}1\",\n",
    "        f\"{v}2\",\n",
    "        color=rgba_to_hex(255, 0, 0, int(255 * s)),\n",
    "        dir=\"both\",\n",
    "    )\n",
    "\n",
    "A = display_graph(\n",
    "    G_both,\n",
    "    layout=\"sfdp\",\n",
    "    Glevels=1,\n",
    "    GK=0.6,\n",
    "    Goutputorder=\"edgesfirst\",\n",
    "    Ecolor=\"gray50\",\n",
    "    Gstart=7,\n",
    ")\n",
    "# A.draw(fig_dir / \"graph_matching.pdf\")\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def edge_similarity(\n",
    "    G1: nx.DiGraph,\n",
    "    G2: nx.DiGraph,\n",
    "    embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    batch_size: int = 512,\n",
    "    match_threshold: float = 0.9,\n",
    "    skip_if_too_slow: bool = True,\n",
    "):\n",
    "    # Skip computation if too slow. Time complexity is O(n^2 m)\n",
    "    s1 = G1.number_of_edges()\n",
    "    s2 = G2.number_of_edges()\n",
    "    n = min(s1, s2)\n",
    "    m = max(s1, s2)\n",
    "\n",
    "    if \"embed\" not in G1.nodes[next(iter(G1.nodes))]:\n",
    "        G1 = embed_graph(G1, embedding_model=embedding_model)\n",
    "    if \"embed\" not in G2.nodes[next(iter(G2.nodes))]:\n",
    "        G2 = embed_graph(G2, embedding_model=embedding_model)\n",
    "\n",
    "    def embed_edges(G, edges):\n",
    "        u_emb = torch.stack([G.nodes[u][\"embed\"] for u, _ in edges])\n",
    "        v_emb = torch.stack([G.nodes[v][\"embed\"] for _, v in edges])\n",
    "        return u_emb, v_emb\n",
    "\n",
    "    def edge_sim(G1, edges1, G2, edges2):\n",
    "        u1_emb, v1_emb = embed_edges(G1, edges1)\n",
    "        u2_emb, v2_emb = embed_edges(G2, edges2)\n",
    "        sim_u = cosine_sim(u1_emb, u2_emb, dim=-1)\n",
    "        sim_v = cosine_sim(v1_emb, v2_emb, dim=-1)\n",
    "        return sim_u, sim_v\n",
    "\n",
    "    sims_u = []\n",
    "    sims_v = []\n",
    "    for edge_batch_1 in batch(G1.edges, batch_size):\n",
    "        sims_u_row = []\n",
    "        sims_v_row = []\n",
    "        for edge_batch_2 in batch(G2.edges, batch_size):\n",
    "            sim_u, sim_v = edge_sim(G1, edge_batch_1, G2, edge_batch_2)\n",
    "            sims_u_row.append(sim_u)\n",
    "            sims_v_row.append(sim_v)\n",
    "        sims_u.append(torch.cat(sims_u_row, dim=-1))\n",
    "        sims_v.append(torch.cat(sims_v_row, dim=-1))\n",
    "    sims_u = torch.cat(sims_u, dim=0)\n",
    "    sims_v = torch.cat(sims_v, dim=0)\n",
    "\n",
    "    # Soft precision, recall, f1\n",
    "    sims = torch.minimum(sims_u, sims_v).cpu().numpy()\n",
    "    row_ind, col_ind = linear_sum_assignment(sims, maximize=True)\n",
    "\n",
    "    return sims, row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "edge_sims, edge_row_ind, edge_col_ind = edge_similarity(G_true, G_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "G_both = nx.DiGraph()\n",
    "for n in G_true.nodes:\n",
    "    G_both.add_node(f\"{n}1\", title=G_true.nodes[n][\"title\"], shape=\"plaintext\")\n",
    "for n in G_pred.nodes:\n",
    "    G_both.add_node(\n",
    "        f\"{n}2\",\n",
    "        title=G_pred.nodes[n][\"title\"],\n",
    "        fontcolor=\"deepskyblue4\",\n",
    "        shape=\"plaintext\",\n",
    "    )\n",
    "\n",
    "for u, v in G_true.edges:\n",
    "    # G_both.add_edge(f\"{u}1\", f\"{v}1\")\n",
    "    G_both.add_edge(f\"{u}1\", f\"{u}{v}1\", arrowhead=\"none\")\n",
    "    G_both.add_edge(f\"{u}{v}1\", f\"{v}1\")\n",
    "    G_both.add_node(f\"{u}{v}1\", title=\"\", shape=\"point\", width=0, height=0)\n",
    "\n",
    "for u, v in G_pred.edges:\n",
    "    # G_both.add_edge(f\"{u}2\", f\"{v}2\", color=\"deepskyblue4\")\n",
    "    G_both.add_edge(f\"{u}2\", f\"{u}{v}2\", color=\"deepskyblue4\", arrowhead=\"none\")\n",
    "    G_both.add_edge(f\"{u}{v}2\", f\"{v}2\", color=\"deepskyblue4\")\n",
    "    G_both.add_node(f\"{u}{v}2\", title=\"\", shape=\"point\", width=0, height=0)\n",
    "\n",
    "for i, j in zip(edge_row_ind, edge_col_ind):\n",
    "    u1, v1 = list(G_true.edges)[i]\n",
    "    u2, v2 = list(G_pred.edges)[j]\n",
    "    s = edge_sims[i, j] / np.max(edge_sims[edge_row_ind, edge_col_ind])\n",
    "    G_both.add_edge(\n",
    "        f\"{u1}{v1}1\",\n",
    "        f\"{u2}{v2}2\",\n",
    "        color=rgba_to_hex(255, 0, 0, int(255 * s)),\n",
    "        dir=\"both\",\n",
    "    )\n",
    "\n",
    "A = display_graph(\n",
    "    G_both,\n",
    "    layout=\"sfdp\",\n",
    "    Glevels=1,\n",
    "    GK=0.4,\n",
    "    Goutputorder=\"edgesfirst\",\n",
    "    Ecolor=\"gray50\",\n",
    "    Gstart=7,\n",
    ")\n",
    "A.draw(fig_dir / \"edge_matching.pdf\")\n",
    "A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-ol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
