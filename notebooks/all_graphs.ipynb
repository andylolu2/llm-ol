{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib_venn\n",
    "import graph_tool.all as gt\n",
    "from tqdm import tqdm\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "from llm_ol.dataset.data_model import load_graph\n",
    "from llm_ol.utils.nx_to_gt import nx_to_gt\n",
    "from llm_ol.experiments.post_processing import hp_search, post_process, PostProcessHP\n",
    "from llm_ol.eval.graph_metrics import edge_precision, edge_recall, edge_f1\n",
    "from metadata import query, query_multiple\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utilities\n",
    "\n",
    "fig_dir = Path(\"out\", \"graphs\")\n",
    "\n",
    "\n",
    "def display_graph(G: nx.Graph, layout: str = \"dot\"):\n",
    "    relabel_map = {}\n",
    "    for n, data in G.nodes(data=True):\n",
    "        relabel_map[n] = data.get(\"title\", n)\n",
    "    G = nx.relabel_nodes(G, relabel_map)\n",
    "    A = nx.nx_agraph.to_agraph(G)\n",
    "    A.node_attr.update(fontname=\"Helvetica\", fontsize=10, shape=\"plaintext\")\n",
    "    A.graph_attr.update(ratio=\"compress\", ranksep=0.25)\n",
    "    A.edge_attr.update(arrowsize=0.5)\n",
    "    A.layout(layout)\n",
    "    display(A)\n",
    "\n",
    "\n",
    "def nth_level_nodes(G: nx.Graph, n: int):\n",
    "    return nx.descendants_at_distance(G, G.graph[\"root\"], n)\n",
    "\n",
    "\n",
    "def nth_level_edges(G: nx.Graph, n: int):\n",
    "    distances = nx.single_source_shortest_path_length(G, G.graph[\"root\"], cutoff=n)\n",
    "    return {(u, v) for u, v in G.edges() if distances.get(u, None) == n}\n",
    "\n",
    "\n",
    "def title(G, n):\n",
    "    return G.nodes[n].get(\"title\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot subgraph induced by paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = query(exp=\"finetune\", step=30000, reweighted=True)\n",
    "G = load_graph(exp.eval_output)\n",
    "G = post_process(G, PostProcessHP(edge_percentile=0.975, merge_nodes_by_lemma=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cutoff = 4\n",
    "node = random.choice(list(G.nodes()))\n",
    "\n",
    "G_sub = nx.DiGraph()\n",
    "for path in nx.all_simple_paths(G, G.graph[\"root\"], node, cutoff=path_cutoff):\n",
    "    for u, v in zip(path[:-1], path[1:]):\n",
    "        G_sub.add_edge(title(G, u), title(G, v))\n",
    "\n",
    "display_graph(G_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the union and intersection of nodes & edges in the train, eval and test graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = query(exp=\"hearst\")\n",
    "G_train = load_graph(exp.train_input)\n",
    "G_eval = load_graph(exp.eval_ground_truth)\n",
    "G_test = load_graph(exp.test_ground_truth)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for level, ax in enumerate(axs[0], start=1):\n",
    "    set1 = nth_level_nodes(G_train, level)\n",
    "    set2 = nth_level_nodes(G_eval, level)\n",
    "    set3 = nth_level_nodes(G_test, level)\n",
    "    matplotlib_venn.venn3([set1, set2, set3], [\"Train\", \"Eval\", \"Test\"], ax=ax)\n",
    "    ax.set_title(f\"Level {level} nodes\")\n",
    "\n",
    "for level, ax in enumerate(axs[1], start=0):\n",
    "    set1 = nth_level_edges(G_train, level)\n",
    "    set2 = nth_level_edges(G_eval, level)\n",
    "    set3 = nth_level_edges(G_test, level)\n",
    "    matplotlib_venn.venn3([set1, set2, set3], [\"Train\", \"Eval\", \"Test\"], ax=ax)\n",
    "    ax.set_title(f\"Level {level} edges\")\n",
    "\n",
    "# fig.savefig(fig_dir / \"wiki_train_eval_test_split.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the nodes & edges coverage by only considering paths of length n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_and_edge_coverage(G: nx.Graph, n: int):\n",
    "    G_gt, nx_to_gt_map, gt_to_nx_map = nx_to_gt(G)\n",
    "\n",
    "    nodes_with_pages = {\n",
    "        node for node, data in G.nodes(data=True) if len(data[\"pages\"]) > 0\n",
    "    }\n",
    "\n",
    "    nodes_covered = set()\n",
    "    edges_covered = set()\n",
    "    for node in tqdm(nodes_with_pages):\n",
    "        for path in gt.all_paths(\n",
    "            G_gt,\n",
    "            source=nx_to_gt_map[G.graph[\"root\"]],\n",
    "            target=nx_to_gt_map[node],\n",
    "            cutoff=n,\n",
    "        ):\n",
    "            edges_covered |= {\n",
    "                (gt_to_nx_map[u], gt_to_nx_map[v]) for u, v in zip(path[:-1], path[1:])\n",
    "            }\n",
    "            nodes_covered |= {gt_to_nx_map[v] for v in path}\n",
    "\n",
    "    assert nodes_covered.issubset(set(G.nodes()))\n",
    "    assert edges_covered.issubset(set(G.edges()))\n",
    "    return (\n",
    "        len(nodes_covered) / G.number_of_nodes(),\n",
    "        len(edges_covered) / G.number_of_edges(),\n",
    "    )\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "xs = np.arange(6)\n",
    "ys = np.array([node_and_edge_coverage(G_train, n) for n in xs])\n",
    "ax.plot(xs, ys[:, 0], label=\"Nodes coverage\")\n",
    "ax.plot(xs, ys[:, 1], label=\"Edges coverage\")\n",
    "fig.legend(loc=\"upper left\")\n",
    "\n",
    "# fig.savefig(fig_dir / \"wiki_test_coverage.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motif analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_polygon_layout(g: gt.Graph, n: int, r: float = 1.0):\n",
    "    pos = g.new_vertex_property(\"vector<double>\")\n",
    "    for i, v in enumerate(g.vertices()):\n",
    "        pos[v] = (\n",
    "            r * np.cos(2 * np.pi * i / n - np.pi / 2),\n",
    "            r * np.sin(2 * np.pi * i / n - np.pi / 2),\n",
    "        )\n",
    "    return pos\n",
    "\n",
    "\n",
    "def count_motifs(Gs: list[nx.Graph], n: int = 3):\n",
    "    motifs_list, counts_list = zip(*[gt.motifs(nx_to_gt(G)[0], n) for G in Gs])\n",
    "    all_motifs = []\n",
    "    all_idx_to_idx = []\n",
    "    for motifs in motifs_list:\n",
    "        idx_to_idx = {}  # idx in all_motifs -> idx in motifs\n",
    "        for i, motif in enumerate(motifs):\n",
    "            for j, existing_motif in enumerate(all_motifs):\n",
    "                if gt.isomorphism(motif, existing_motif):\n",
    "                    idx_to_idx[j] = i\n",
    "                    break\n",
    "            else:\n",
    "                all_motifs.append(motif)\n",
    "                idx_to_idx[len(all_motifs) - 1] = i\n",
    "        all_idx_to_idx.append(idx_to_idx)\n",
    "\n",
    "    all_counts = []\n",
    "    for idx_to_idx, counts in zip(all_idx_to_idx, counts_list):\n",
    "        all_counts.append([])\n",
    "        for j in range(len(all_motifs)):\n",
    "            all_counts[-1].append(counts[idx_to_idx[j]] if j in idx_to_idx else 0)\n",
    "\n",
    "    return all_motifs, all_counts\n",
    "\n",
    "\n",
    "motifs, counts = count_motifs([G_train, G_eval, G_test])\n",
    "\n",
    "# sort by the sum of counts\n",
    "counts = np.array(counts)\n",
    "order = np.argsort(counts.sum(axis=0))[::-1]\n",
    "counts = counts[:, order]\n",
    "motifs = [motifs[i] for i in order]\n",
    "\n",
    "# only keep the top n motifs\n",
    "n = 5\n",
    "counts = counts[:, :n]\n",
    "motifs = motifs[:n]\n",
    "\n",
    "# normalize the counts\n",
    "counts = counts / counts.sum(axis=1)[:, None]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"count\": counts.reshape(-1),\n",
    "        \"motif\": np.tile(np.arange(len(motifs)), counts.shape[0]),\n",
    "        \"graph\": np.repeat([\"Train\", \"Eval\", \"Test\"], len(motifs)),\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "sns.barplot(data=df, x=\"motif\", y=\"count\", hue=\"graph\", ax=ax)\n",
    "ax.set(xticklabels=[], xlabel=\"\", ylabel=\"Fraction of motifs\")\n",
    "\n",
    "# draw the motif graph as the x labels\n",
    "res = 5\n",
    "r = 0.7\n",
    "pad = 0.7\n",
    "for motif, xticklabel in zip(motifs, ax.get_xticklabels()):\n",
    "    gt.graph_draw(\n",
    "        motif,\n",
    "        pos=regular_polygon_layout(motif, motif.num_vertices(), r),\n",
    "        vertex_fill_color=\"black\",\n",
    "        # vertex_size=5,\n",
    "        edge_color=\"black\",\n",
    "        output_size=(30 * res, 30 * res),\n",
    "        output=\"/tmp/motif.png\",\n",
    "        ink_scale=0.6,\n",
    "        fit_view=(-r - pad, -r - pad, 2 * (r + pad), 2 * (r + pad)),\n",
    "    )\n",
    "    im = plt.imread(\"/tmp/motif.png\")\n",
    "    ib = OffsetImage(im, zoom=1 / res, snap=True, resample=True)\n",
    "    ib.image.axes = ax\n",
    "    ab = AnnotationBbox(\n",
    "        ib,\n",
    "        xticklabel.get_position(),\n",
    "        frameon=False,\n",
    "        box_alignment=(0.5, 1.1),\n",
    "    )\n",
    "    ax.add_artist(ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AP vs training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = query_multiple(exp=\"finetune\", version=2)\n",
    "\n",
    "assert len({exp.eval_ground_truth for exp in exps}) == 1\n",
    "G_true = load_graph(exps[0].eval_ground_truth)\n",
    "\n",
    "\n",
    "def prec_recall_curve(thresholds, G_pred, G_true):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for edge_percentile in tqdm(thresholds):\n",
    "        G_pruned = post_process(\n",
    "            G_pred,\n",
    "            PostProcessHP(\n",
    "                edge_percentile=edge_percentile,\n",
    "                merge_nodes_by_lemma=False,\n",
    "                prune_unconnected_nodes=True,\n",
    "            ),\n",
    "        )\n",
    "        prec = edge_precision(G_pruned, G_true)\n",
    "        rec = edge_recall(G_pruned, G_true)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "\n",
    "    return np.array(precisions), np.array(recalls)\n",
    "\n",
    "\n",
    "data = []\n",
    "for exp in exps:\n",
    "    G = load_graph(exp.eval_output)\n",
    "    thresholds = 1 - np.geomspace(1 / G.number_of_edges(), 1, 11)\n",
    "    precisions, recalls = prec_recall_curve(thresholds, G, G_true)\n",
    "    data.append(\n",
    "        {\n",
    "            \"step\": exp.step,\n",
    "            \"reweighted\": exp.reweighted,\n",
    "            \"precisions\": precisions,\n",
    "            \"recalls\": recalls,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_ap(group):\n",
    "    ap = np.trapz(group[\"precisions\"], group[\"recalls\"])\n",
    "    return pd.Series({\"ap\": ap})\n",
    "\n",
    "\n",
    "df = pd.concat([pd.DataFrame(d) for d in data])\n",
    "df[\"f1\"] = 2 * df[\"precisions\"] * df[\"recalls\"] / (df[\"precisions\"] + df[\"recalls\"])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df, x=\"recalls\", y=\"precisions\", hue=\"step\", style=\"reweighted\", ax=axs[0]\n",
    ")\n",
    "df_ap = df.groupby([\"step\", \"reweighted\"]).apply(agg_ap)\n",
    "sns.lineplot(data=df_ap, x=\"step\", y=\"ap\", style=\"reweighted\", ax=axs[1])\n",
    "df_f1 = df.groupby([\"step\", \"reweighted\"]).agg({\"f1\": \"max\"})\n",
    "sns.lineplot(data=df_f1, x=\"step\", y=\"f1\", style=\"reweighted\", ax=axs[2])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_ap(group):\n",
    "    ap = np.trapz(group[\"precisions\"], group[\"recalls\"])\n",
    "    return pd.Series({\"ap\": ap})\n",
    "\n",
    "\n",
    "df = pd.concat([pd.DataFrame(d) for d in data])\n",
    "df[\"f1\"] = 2 * df[\"precisions\"] * df[\"recalls\"] / (df[\"precisions\"] + df[\"recalls\"])\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df, x=\"recalls\", y=\"precisions\", hue=\"step\", style=\"reweighted\", ax=axs[0]\n",
    ")\n",
    "df_ap = df.groupby([\"step\", \"reweighted\"]).apply(agg_ap)\n",
    "sns.lineplot(data=df_ap, x=\"step\", y=\"ap\", style=\"reweighted\", ax=axs[1])\n",
    "df_f1 = df.groupby([\"step\", \"reweighted\"]).agg({\"f1\": \"max\"})\n",
    "sns.lineplot(data=df_f1, x=\"step\", y=\"f1\", style=\"reweighted\", ax=axs[2])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = query_multiple(exp=\"finetune\")\n",
    "\n",
    "assert len({exp.eval_ground_truth for exp in exps}) == 1\n",
    "G_true = load_graph(exps[0].eval_ground_truth)\n",
    "\n",
    "n_levels = 4\n",
    "\n",
    "\n",
    "data = []\n",
    "for exp in exps:\n",
    "    G = load_graph(exp.eval_output)\n",
    "    for level in range(n_levels):\n",
    "        target_edges = [\n",
    "            (title(G_true, u), title(G_true, v))\n",
    "            for u, v in nth_level_edges(G_true, level)\n",
    "        ]\n",
    "        weights = [\n",
    "            G.edges[u, v][\"weight\"] if G.has_edge(u, v) else 0 for u, v in target_edges\n",
    "        ]\n",
    "        data.append(\n",
    "            {\n",
    "                \"step\": exp.step,\n",
    "                \"reweighted\": exp.reweighted,\n",
    "                \"level\": level,\n",
    "                \"weight\": weights,\n",
    "            }\n",
    "        )\n",
    "\n",
    "df = pd.concat([pd.DataFrame(d) for d in data])\n",
    "\n",
    "fig, axs = plt.subplots(1, n_levels, figsize=(4 * n_levels, 3))\n",
    "\n",
    "for level, ax in enumerate(axs):\n",
    "    sns.lineplot(\n",
    "        data=df[df[\"level\"] == level],\n",
    "        x=\"step\",\n",
    "        y=\"weight\",\n",
    "        hue=\"reweighted\",\n",
    "        ax=ax,\n",
    "        errorbar=None,\n",
    "    )\n",
    "    ax.set(title=f\"Mean weight of level {level} edges\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"finetune_detailed_edge_weights_change.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-ol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
