{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import json\n",
    "import dataclasses\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib_venn\n",
    "import graph_tool.all as gt\n",
    "from tqdm import tqdm\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "from llm_ol.dataset.data_model import load_graph\n",
    "from llm_ol.utils.nx_to_gt import nx_to_gt\n",
    "from llm_ol.experiments.post_processing import hp_search, post_process, PostProcessHP\n",
    "from llm_ol.eval.graph_metrics import (\n",
    "    edge_prec_recall_f1,\n",
    "    graph_fuzzy_match,\n",
    "    edge_similarity,\n",
    ")\n",
    "from llm_ol.utils import sized_subplots\n",
    "from metadata import query, query_multiple\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Some utilities\n",
    "\n",
    "fig_dir = Path(\"out\", \"graphs\")\n",
    "\n",
    "\n",
    "def display_graph(G: nx.Graph, layout: str = \"dot\", **kwargs):\n",
    "    relabel_map = {}\n",
    "    for n, data in G.nodes(data=True):\n",
    "        relabel_map[n] = data.get(\"title\", n)\n",
    "    G = nx.relabel_nodes(G, relabel_map)\n",
    "    for n, data in G.nodes(data=True):\n",
    "        data.clear()\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        data.clear()\n",
    "\n",
    "    A = nx.nx_agraph.to_agraph(G)\n",
    "    A.node_attr.update(fontname=\"Helvetica\", fontsize=10, shape=\"plaintext\")\n",
    "    A.graph_attr.update(ratio=\"compress\")\n",
    "    A.edge_attr.update(arrowsize=0.5)\n",
    "    for k, v in kwargs.items():\n",
    "        if k.startswith(\"G\"):\n",
    "            A.graph_attr[k[1:]] = v\n",
    "        elif k.startswith(\"N\"):\n",
    "            A.node_attr[k[1:]] = v\n",
    "        elif k.startswith(\"E\"):\n",
    "            A.edge_attr[k[1:]] = v\n",
    "    A.layout(layout)\n",
    "    return A\n",
    "\n",
    "\n",
    "def nth_level_nodes(G: nx.Graph, n: int):\n",
    "    return nx.descendants_at_distance(G, G.graph[\"root\"], n)\n",
    "\n",
    "\n",
    "def nth_level_edges(G: nx.Graph, n: int):\n",
    "    distances = nx.single_source_shortest_path_length(G, G.graph[\"root\"], cutoff=n)\n",
    "    return {(u, v) for u, v in G.edges() if distances.get(u, None) == n}\n",
    "\n",
    "\n",
    "def title(G, n):\n",
    "    return G.nodes[n].get(\"title\", n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# G = load_graph(\"out/data/wikipedia/v2/full/graph_depth_3.json\")\n",
    "G = load_graph(\"out/data/arxiv/v2/full/full_graph.json\")\n",
    "pages = set()\n",
    "for n, data in G.nodes(data=True):\n",
    "    pages.update([page[\"id\"] for page in data[\"pages\"]])\n",
    "print(G.number_of_nodes(), G.number_of_edges(), len(pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot subgraph induced by paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# exp = query(exp=\"finetune\", dataset=\"arxiv/v2\", reweighted=True)\n",
    "exp = query(exp=\"prompting\", dataset=\"wikipedia/v2\", k_shot=0)\n",
    "# exp = query(exp=\"memorisation\", dataset=\"arxiv/v2\")\n",
    "G = load_graph(exp.test_output)\n",
    "G = post_process(\n",
    "    G,\n",
    "    PostProcessHP(\n",
    "        absolute_percentile=0.984719,\n",
    "        relative_percentile=0.701893,\n",
    "        prune_unconnected_nodes=False,\n",
    "        add_root=False,\n",
    "    ),\n",
    "    # G,\n",
    "    # PostProcessHP(**exp.best_hp(\"edge_similarity\")),\n",
    ")\n",
    "print(G.number_of_nodes(), G.number_of_edges())\n",
    "\n",
    "G_true = load_graph(exp.test_ground_truth)\n",
    "print(G_true.number_of_nodes(), G_true.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "exp = query(exp=\"hearst\", dataset=\"wikipedia/v2\")\n",
    "G = load_graph(exp.train_input)\n",
    "page_parents = defaultdict(set)\n",
    "page_lookup = {}\n",
    "for n, data in G.nodes(data=True):\n",
    "    for page in data[\"pages\"]:\n",
    "        page_parents[page[\"id\"]].add(n)\n",
    "        page_lookup[page[\"id\"]] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "path_cutoff = 4\n",
    "page = random.choice(list(page_parents))\n",
    "while len(page_parents[page]) <= 1:\n",
    "    page = random.choice(list(page_parents))\n",
    "\n",
    "print(page_lookup[page])\n",
    "\n",
    "G_sub = nx.DiGraph()\n",
    "for node in page_parents[page]:\n",
    "    for path in nx.all_simple_paths(G, G.graph[\"root\"], node, cutoff=path_cutoff):\n",
    "        for u, v in zip(path[:-1], path[1:]):\n",
    "            G_sub.add_edge(title(G, u), title(G, v))\n",
    "\n",
    "A = display_graph(G_sub, Granksep=0.3)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# A.draw(str(fig_dir / f\"{page_lookup[page]['title']}.pdf\"))\n",
    "page_lookup[page][\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arXiv thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "G = load_graph(\"out/experiments/finetune/arxiv/v3/288/all/graph.json\")\n",
    "exp = query(exp=\"finetune\", dataset=\"arxiv/v2\", reweighted=True)\n",
    "hp = PostProcessHP(**exp.best_hp(\"edge_soft_f1\"))\n",
    "G = post_process(G, hp)\n",
    "G = nx.subgraph(G, nx.descendants(G, G.graph[\"root\"]) | {G.graph[\"root\"]})\n",
    "print(hp)\n",
    "print(G.number_of_nodes(), G.number_of_edges())\n",
    "\n",
    "# A = display_graph(G, layout=\"dot\")\n",
    "# A = display_graph(G, layout=\"sfdp\", Glevels=2, GK=0.8, Gstart=2)\n",
    "# A = display_graph(G, layout=\"neato\", Elen=2, Gstart=0)\n",
    "A = display_graph(G, layout=\"twopi\", Granksep=3, Gstart=0)\n",
    "# A.draw(fig_dir / f\"{exp.name}_{exp.dataset.replace('/', '_')}_output.pdf\")\n",
    "# print(A.to_string())\n",
    "A\n",
    "\n",
    "# relabel_map = {}\n",
    "# for n, data in G.nodes(data=True):\n",
    "#     relabel_map[n] = data.get(\"title\", n)\n",
    "# G = nx.relabel_nodes(G, relabel_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "exp = query(exp=\"finetune\", dataset=\"arxiv/v2\", reweighted=True)\n",
    "G = load_graph(exp.test_ground_truth)\n",
    "print(G.number_of_nodes(), G.number_of_edges())\n",
    "\n",
    "# A = display_graph(G, layout=\"dot\")\n",
    "# A = display_graph(G, layout=\"sfdp\", Glevels=1, GK=0.6, Gstart=2)\n",
    "# A = display_graph(G, layout=\"neato\", Elen=1.5, Gstart=0)\n",
    "A = display_graph(G, layout=\"twopi\", Granksep=2, Gstart=2)\n",
    "# A = display_graph(G, layout=\"circo\", Goverlap=\"compress\")\n",
    "# A.draw(fig_dir / f\"{exp.name}_test_output.pdf\")\n",
    "# print(A.to_string())\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the union and intersection of nodes & edges in the train, eval and test graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"wikipedia/v2\": \"Wikipedia\",\n",
    "    \"arxiv/v2\": \"arXiv\",\n",
    "}\n",
    "\n",
    "for dataset, name in datasets.items():\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    exp = query(exp=\"hearst\", dataset=dataset)\n",
    "    G_train = load_graph(exp.train_input)\n",
    "    G_eval = load_graph(exp.eval_ground_truth)\n",
    "    G_test = load_graph(exp.test_ground_truth)\n",
    "\n",
    "    train = set(G_train.nodes())\n",
    "    eval = set(G_eval.nodes())\n",
    "    test = set(G_test.nodes())\n",
    "\n",
    "    matplotlib_venn.venn3([train, eval, test], [\"Train\", \"Eval\", \"Test\"], ax=ax)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fig_dir / f\"{name}_train_eval_test_split.pdf\")\n",
    "\n",
    "\n",
    "# fig.savefig(fig_dir / \"wiki_train_eval_test_split.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the nodes & edges coverage by only considering paths of length n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_and_edge_coverage(G: nx.Graph, n: int):\n",
    "    G_gt, nx_to_gt_map, gt_to_nx_map = nx_to_gt(G)\n",
    "\n",
    "    nodes_with_pages = {\n",
    "        node for node, data in G.nodes(data=True) if len(data[\"pages\"]) > 0\n",
    "    }\n",
    "\n",
    "    nodes_covered = set()\n",
    "    edges_covered = set()\n",
    "    for node in tqdm(nodes_with_pages):\n",
    "        for path in gt.all_paths(\n",
    "            G_gt,\n",
    "            source=nx_to_gt_map[G.graph[\"root\"]],\n",
    "            target=nx_to_gt_map[node],\n",
    "            cutoff=n,\n",
    "        ):\n",
    "            edges_covered |= {\n",
    "                (gt_to_nx_map[u], gt_to_nx_map[v]) for u, v in zip(path[:-1], path[1:])\n",
    "            }\n",
    "            nodes_covered |= {gt_to_nx_map[v] for v in path}\n",
    "\n",
    "    assert nodes_covered.issubset(set(G.nodes()))\n",
    "    assert edges_covered.issubset(set(G.edges()))\n",
    "    return (\n",
    "        len(nodes_covered) / G.number_of_nodes(),\n",
    "        len(edges_covered) / G.number_of_edges(),\n",
    "    )\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "xs = np.arange(6)\n",
    "ys = np.array([node_and_edge_coverage(G_train, n) for n in xs])\n",
    "ax.plot(xs, ys[:, 0], label=\"Nodes coverage\")\n",
    "ax.plot(xs, ys[:, 1], label=\"Edges coverage\")\n",
    "fig.legend(loc=\"upper left\")\n",
    "\n",
    "# fig.savefig(fig_dir / \"wiki_test_coverage.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motif analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def regular_polygon_layout(g: gt.Graph, n: int, r: float = 1.0):\n",
    "    pos = g.new_vertex_property(\"vector<double>\")\n",
    "    for i, v in enumerate(g.vertices()):\n",
    "        pos[v] = (\n",
    "            r * np.cos(2 * np.pi * i / n - np.pi / 2),\n",
    "            r * np.sin(2 * np.pi * i / n - np.pi / 2),\n",
    "        )\n",
    "    return pos\n",
    "\n",
    "\n",
    "def count_motifs(Gs: list[nx.Graph], n: int = 3):\n",
    "    motifs_list, counts_list = zip(*[gt.motifs(nx_to_gt(G)[0], n) for G in Gs])\n",
    "    all_motifs = []\n",
    "    all_idx_to_idx = []\n",
    "    for motifs in motifs_list:\n",
    "        idx_to_idx = {}  # idx in all_motifs -> idx in motifs\n",
    "        for i, motif in enumerate(motifs):\n",
    "            for j, existing_motif in enumerate(all_motifs):\n",
    "                if gt.isomorphism(motif, existing_motif):\n",
    "                    idx_to_idx[j] = i\n",
    "                    break\n",
    "            else:\n",
    "                all_motifs.append(motif)\n",
    "                idx_to_idx[len(all_motifs) - 1] = i\n",
    "        all_idx_to_idx.append(idx_to_idx)\n",
    "\n",
    "    all_counts = []\n",
    "    for idx_to_idx, counts in zip(all_idx_to_idx, counts_list):\n",
    "        all_counts.append([])\n",
    "        for j in range(len(all_motifs)):\n",
    "            all_counts[-1].append(counts[idx_to_idx[j]] if j in idx_to_idx else 0)\n",
    "\n",
    "    return all_motifs, all_counts\n",
    "\n",
    "\n",
    "exps = [\n",
    "    query(exp=\"prompting\", k_shot=0, dataset=\"arxiv/v2\"),\n",
    "    query(exp=\"finetune\", reweighted=True, dataset=\"arxiv/v2\"),\n",
    "    query(exp=\"finetune\", reweighted=False, dataset=\"arxiv/v2\"),\n",
    "    # query(exp=\"finetune\", reweighted=True, dataset=\"wikipedia/v2\", step=\"final\"),\n",
    "    # query(exp=\"finetune\", reweighted=False, dataset=\"wikipedia/v2\", step=\"final\"),\n",
    "    # query(exp=\"prompting\", k_shot=3, dataset=\"wikipedia/v2\"),\n",
    "]\n",
    "assert all(exp.train_input == exps[0].train_input for exp in exps)\n",
    "assert all(exp.eval_ground_truth == exps[0].eval_ground_truth for exp in exps)\n",
    "assert all(exp.test_ground_truth == exps[0].test_ground_truth for exp in exps)\n",
    "\n",
    "labels = [exp.name for exp in exps] + [\"Ground truth\"]\n",
    "Gs = [\n",
    "    post_process(\n",
    "        load_graph(exp.test_output), PostProcessHP(**exp.best_hp(\"edge_similarity\"))\n",
    "    )\n",
    "    for exp in exps\n",
    "]\n",
    "Gs.append(load_graph(exps[0].test_ground_truth))\n",
    "\n",
    "motifs, counts = count_motifs(Gs)\n",
    "print(counts)\n",
    "\n",
    "# sort by the sum of counts\n",
    "counts = np.array(counts)\n",
    "order = np.argsort(counts.sum(axis=0))[::-1]\n",
    "counts = counts[:, order]\n",
    "motifs = [motifs[i] for i in order]\n",
    "\n",
    "# only keep the top n motifs\n",
    "# n = 10\n",
    "# counts = counts[:, :n]\n",
    "# motifs = motifs[:n]\n",
    "\n",
    "# normalize the counts\n",
    "counts = counts / counts.sum(axis=1)[:, None]\n",
    "\n",
    "df_test = pd.DataFrame(\n",
    "    {\n",
    "        \"count\": counts.reshape(-1),\n",
    "        \"motif\": np.tile(np.arange(len(motifs)), counts.shape[0]),\n",
    "        \"graph\": np.repeat(labels, len(motifs)),\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "sns.barplot(data=df_test, x=\"motif\", y=\"count\", hue=\"graph\", ax=ax)\n",
    "ax.set(xticklabels=[], xlabel=\"\", ylabel=\"Fraction of motifs\")\n",
    "\n",
    "# draw the motif graph as the x labels\n",
    "res = 5\n",
    "r = 0.7\n",
    "pad = 0.7\n",
    "for motif, xticklabel in zip(motifs, ax.get_xticklabels()):\n",
    "    gt.graph_draw(\n",
    "        motif,\n",
    "        pos=regular_polygon_layout(motif, motif.num_vertices(), r),\n",
    "        vertex_fill_color=\"black\",\n",
    "        # vertex_size=5,\n",
    "        edge_color=\"black\",\n",
    "        output_size=(30 * res, 30 * res),\n",
    "        output=\"/tmp/motif.png\",\n",
    "        ink_scale=0.6,\n",
    "        fit_view=(-r - pad, -r - pad, 2 * (r + pad), 2 * (r + pad)),\n",
    "    )\n",
    "    im = plt.imread(\"/tmp/motif.png\")\n",
    "    ib = OffsetImage(im, zoom=1 / res, snap=True, resample=True)\n",
    "    ib.image.axes = ax\n",
    "    ab = AnnotationBbox(\n",
    "        ib,\n",
    "        xticklabel.get_position(),\n",
    "        frameon=False,\n",
    "        box_alignment=(0.5, 1.1),\n",
    "    )\n",
    "    ax.add_artist(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8)\n",
    "counts_all = np.zeros((len(labels), 54))\n",
    "counts_all[:, : counts.shape[1]] = counts\n",
    "counts_all += 1\n",
    "counts_all /= counts_all.sum(axis=1)[:, None]\n",
    "counts_true = counts_all[-1]\n",
    "\n",
    "kl = np.sum(counts_true * np.log(counts_true / counts_all), axis=1)\n",
    "kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AP vs training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = query_multiple(exp=\"finetune\", version=2)\n",
    "\n",
    "assert len({exp.eval_ground_truth for exp in exps}) == 1\n",
    "G_true = load_graph(exps[0].eval_ground_truth)\n",
    "\n",
    "\n",
    "def prec_recall_curve(thresholds, G_pred, G_true):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for edge_percentile in tqdm(thresholds):\n",
    "        G_pruned = post_process(\n",
    "            G_pred,\n",
    "            PostProcessHP(\n",
    "                absolute_percentile=edge_percentile,\n",
    "                merge_nodes_by_lemma=False,\n",
    "                prune_unconnected_nodes=True,\n",
    "            ),\n",
    "        )\n",
    "        prec = edge_precision(G_pruned, G_true)\n",
    "        rec = edge_recall(G_pruned, G_true)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "\n",
    "    return np.array(precisions), np.array(recalls)\n",
    "\n",
    "\n",
    "data = []\n",
    "for exp in exps:\n",
    "    G = load_graph(exp.eval_output)\n",
    "    thresholds = 1 - np.geomspace(1 / G.number_of_edges(), 1, 11)\n",
    "    precisions, recalls = prec_recall_curve(thresholds, G, G_true)\n",
    "    data.append(\n",
    "        {\n",
    "            \"step\": exp.step,\n",
    "            \"reweighted\": exp.reweighted,\n",
    "            \"precisions\": precisions,\n",
    "            \"recalls\": recalls,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_ap(group):\n",
    "    ap = np.trapz(group[\"precisions\"], group[\"recalls\"])\n",
    "    return pd.Series({\"ap\": ap})\n",
    "\n",
    "\n",
    "df_test = pd.concat([pd.DataFrame(d) for d in data])\n",
    "df_test[\"f1\"] = (\n",
    "    2\n",
    "    * df_test[\"precisions\"]\n",
    "    * df_test[\"recalls\"]\n",
    "    / (df_test[\"precisions\"] + df_test[\"recalls\"])\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_test, x=\"recalls\", y=\"precisions\", hue=\"step\", style=\"reweighted\", ax=axs[0]\n",
    ")\n",
    "df_ap = df_test.groupby([\"step\", \"reweighted\"]).apply(agg_ap)\n",
    "sns.lineplot(data=df_ap, x=\"step\", y=\"ap\", style=\"reweighted\", ax=axs[1])\n",
    "df_f1 = df_test.groupby([\"step\", \"reweighted\"]).agg({\"f1\": \"max\"})\n",
    "sns.lineplot(data=df_f1, x=\"step\", y=\"f1\", style=\"reweighted\", ax=axs[2])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = query_multiple(exp=\"finetune\", version=1)\n",
    "\n",
    "assert len({exp.eval_ground_truth for exp in exps}) == 1\n",
    "G_true = load_graph(exps[0].eval_ground_truth)\n",
    "\n",
    "n_levels = 4\n",
    "\n",
    "\n",
    "data = []\n",
    "for exp in exps:\n",
    "    G = load_graph(exp.eval_output)\n",
    "    for level in range(n_levels):\n",
    "        target_edges = [\n",
    "            (title(G_true, u), title(G_true, v))\n",
    "            for u, v in nth_level_edges(G_true, level)\n",
    "        ]\n",
    "        weights = [\n",
    "            G.edges[u, v][\"weight\"] if G.has_edge(u, v) else 0 for u, v in target_edges\n",
    "        ]\n",
    "        data.append(\n",
    "            {\n",
    "                \"step\": exp.step,\n",
    "                \"reweighted\": exp.reweighted,\n",
    "                \"level\": level,\n",
    "                \"weight\": weights,\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_test = pd.concat([pd.DataFrame(d) for d in data])\n",
    "\n",
    "fig, axs = plt.subplots(1, n_levels, figsize=(4 * n_levels, 3))\n",
    "\n",
    "for level, ax in enumerate(axs):\n",
    "    sns.lineplot(\n",
    "        data=df_test[df_test[\"level\"] == level],\n",
    "        x=\"step\",\n",
    "        y=\"weight\",\n",
    "        hue=\"reweighted\",\n",
    "        ax=ax,\n",
    "        errorbar=(\"ci\", 90),\n",
    "    )\n",
    "    ax.set(title=f\"Mean weight of level {level} edges\")\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(fig_dir / \"finetune_detailed_edge_weights_change.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HP results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    \"wikipedia_v2\": \"Wikipedia\",\n",
    "    \"arxiv_v2\": \"arXiv\",\n",
    "}\n",
    "metrics = {\n",
    "    # \"motif_kl\": \"Motif KL\",\n",
    "    \"edge_f1\": \"Literal F1 ($\\\\uparrow$)\",\n",
    "    \"edge_hard_f1\": \"Fuzzy F1 ($\\\\uparrow$)\",\n",
    "    \"edge_soft_f1\": \"Continuous F1 ($\\\\uparrow$)\",\n",
    "    \"graph_soft_f1\": \"Graph F1 ($\\\\uparrow$)\",\n",
    "    \"motif_wass\": \"Motif dist. ($\\\\downarrow$)\",\n",
    "    # \"graph_hard_f1\": \"Graph hard F1\",\n",
    "}\n",
    "data = []\n",
    "for dataset, dataset_name in dataset.items():\n",
    "    with open(f\"out/eval/{dataset}/test_metrics.jsonl\") as f:\n",
    "        data += [{**json.loads(line), \"dataset\": dataset_name} for line in f]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[[\"dataset\", \"name\"] + list(metrics.keys())]\n",
    "df = df.rename(columns=metrics).rename(columns={\"dataset\": \"Dataset\", \"name\": \"Method\"})\n",
    "\n",
    "# make dataset and name hierarchical index\n",
    "df = df.set_index([\"Dataset\", \"Method\"])\n",
    "# print(df.to_latex(float_format=\"%.3f\"))\n",
    "display(df)\n",
    "\n",
    "# plot for each dataset\n",
    "for dataset in df.index.get_level_values(\"Dataset\").unique():\n",
    "    fig, axs = sized_subplots(n_axes=len(metrics), n_cols=3, ax_size=(4, 2))\n",
    "    axs = axs.flatten()\n",
    "    for metric, ax in zip(metrics.values(), axs):\n",
    "        sns.barplot(\n",
    "            data=df.loc[dataset].sort_values(metric), x=metric, y=\"Method\", ax=ax\n",
    "        )\n",
    "        ax.set(ylabel=\"\")\n",
    "    fig.tight_layout()\n",
    "    # fig.savefig(fig_dir / f\"{dataset}_test_metrics.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def motifs_kl(G_pred: nx.Graph, G_true: nx.Graph, n: int = 3):\n",
    "    motifs_pred, counts_pred = gt.motifs(nx_to_gt(G_pred)[0], n)\n",
    "    motifs_true, counts_true = gt.motifs(nx_to_gt(G_true)[0], n)\n",
    "\n",
    "    all_motifs = motifs_pred[::]\n",
    "    for motif in motifs_true:\n",
    "        for existing_motif in all_motifs:\n",
    "            if gt.isomorphism(motif, existing_motif):\n",
    "                break\n",
    "        else:\n",
    "            all_motifs.append(motif)\n",
    "    all_counts_pred = np.zeros(len(all_motifs))\n",
    "    all_counts_true = np.zeros(len(all_motifs))\n",
    "    for i, motif in enumerate(motifs_pred):\n",
    "        for j, existing_motif in enumerate(all_motifs):\n",
    "            if gt.isomorphism(motif, existing_motif):\n",
    "                all_counts_pred[j] = counts_pred[i]\n",
    "                break\n",
    "    for i, motif in enumerate(motifs_true):\n",
    "        for j, existing_motif in enumerate(all_motifs):\n",
    "            if gt.isomorphism(motif, existing_motif):\n",
    "                all_counts_true[j] = counts_true[i]\n",
    "                break\n",
    "\n",
    "    # Plus one smoothing\n",
    "    all_counts_pred += 1\n",
    "    all_counts_true += 1\n",
    "    all_counts_pred /= all_counts_pred.sum()\n",
    "    all_counts_true /= all_counts_true.sum()\n",
    "\n",
    "    kl = np.sum(all_counts_true * np.log(all_counts_true / all_counts_pred))\n",
    "    return kl\n",
    "\n",
    "\n",
    "def evaluate(G, G_true, hp):\n",
    "    G = post_process(G, hp)\n",
    "    precision, recall, f1 = edge_prec_recall_f1(G, G_true)\n",
    "    soft_precision, soft_recall, soft_f1, hard_precision, hard_recall, hard_f1 = (\n",
    "        edge_similarity(G, G_true, match_threshold=0.75**2)\n",
    "    )\n",
    "    (\n",
    "        soft_graph_precision,\n",
    "        soft_graph_recall,\n",
    "        soft_graph_f1,\n",
    "        hard_graph_precision,\n",
    "        hard_graph_recall,\n",
    "        hard_graph_f1,\n",
    "    ) = graph_fuzzy_match(G, G_true, threshold=0.75, direction=\"undirected\")\n",
    "\n",
    "    motif_kl = motifs_kl(G, G_true)\n",
    "\n",
    "    return {\n",
    "        \"edge_f1\": f1,\n",
    "        \"edge_precision\": precision,\n",
    "        \"edge_recall\": recall,\n",
    "        \"edge_soft_precision\": soft_precision,\n",
    "        \"edge_soft_recall\": soft_recall,\n",
    "        \"edge_soft_f1\": soft_f1,\n",
    "        \"edge_hard_precision\": hard_precision,\n",
    "        \"edge_hard_recall\": hard_recall,\n",
    "        \"edge_hard_f1\": hard_f1,\n",
    "        \"graph_soft_precision\": soft_graph_precision,\n",
    "        \"graph_soft_recall\": soft_graph_recall,\n",
    "        \"graph_soft_f1\": soft_graph_f1,\n",
    "        \"graph_hard_precision\": hard_graph_precision,\n",
    "        \"graph_hard_recall\": hard_graph_recall,\n",
    "        \"graph_hard_f1\": hard_graph_f1,\n",
    "        \"motif_kl\": motif_kl,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "exp = query(exp=\"finetune\", reweighted=True, dataset=\"arxiv/v2\")\n",
    "G = load_graph(exp.test_output)\n",
    "G = post_process(G, PostProcessHP(**exp.best_hp(\"edge_soft_f1\")))\n",
    "G_true = load_graph(exp.test_ground_truth)\n",
    "\n",
    "motifs_kl(G, G_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset = \"arxiv/v2\"\n",
    "exps = [\n",
    "    query(exp=\"prompting\", k_shot=0, dataset=dataset),\n",
    "    # query(exp=\"prompting\", k_shot=1, dataset=dataset),\n",
    "    query(exp=\"prompting\", k_shot=3, dataset=dataset),\n",
    "    query(exp=\"memorisation\", dataset=dataset),\n",
    "    # query(exp=\"hearst\", dataset=dataset),\n",
    "    # query(exp=\"rebel\", dataset=dataset),\n",
    "    query(exp=\"finetune\", reweighted=False, dataset=dataset),\n",
    "    query(exp=\"finetune\", reweighted=True, dataset=dataset),\n",
    "]\n",
    "\n",
    "\n",
    "def evaluate_test_output(exp):\n",
    "    G = load_graph(exp.test_output)\n",
    "    G_true = load_graph(exp.test_ground_truth)\n",
    "    hp = PostProcessHP(**exp.best_hp(\"edge_soft_f1\"))\n",
    "    metrics = evaluate(G, G_true, hp)\n",
    "    return {\"name\": exp.name, **metrics, **dataclasses.asdict(hp)}\n",
    "\n",
    "\n",
    "data = []\n",
    "for exp in exps:\n",
    "    data.append(evaluate_test_output(exp))\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"edge_f1\",\n",
    "    \"motif_kl\",\n",
    "    \"edge_soft_f1\",\n",
    "    \"edge_hard_f1\",\n",
    "    \"graph_soft_f1\",\n",
    "    \"graph_hard_f1\",\n",
    "]\n",
    "fig, axs = sized_subplots(n_axes=len(metrics), n_cols=2, ax_size=(4, 2))\n",
    "axs = axs.flatten()\n",
    "for metric, ax in zip(metrics, axs):\n",
    "    sns.barplot(data=df.sort_values(metric), y=\"name\", x=metric, ax=ax)\n",
    "    ax.set(title=metric)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(fig_dir / f\"{dataset.replace('/', '_')}_test_metrics.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dataset = \"wikipedia/v2\"\n",
    "exps = [\n",
    "    query(exp=\"prompting\", k_shot=0, dataset=dataset),\n",
    "    # query(exp=\"prompting\", k_shot=1, dataset=dataset),\n",
    "    query(exp=\"prompting\", k_shot=3, dataset=dataset),\n",
    "    query(exp=\"memorisation\", dataset=dataset),\n",
    "    # query(exp=\"hearst\", dataset=dataset),\n",
    "    # query(exp=\"rebel\", dataset=dataset),\n",
    "    query(exp=\"finetune\", reweighted=False, dataset=dataset),\n",
    "    query(exp=\"finetune\", reweighted=True, dataset=dataset),\n",
    "    # query(exp=\"finetune\", step=10000, version=3),\n",
    "    # query(exp=\"finetune\", step=15000, version=3),\n",
    "    # query(exp=\"finetune\", step=16500, version=1, reweighted=False),\n",
    "]\n",
    "\n",
    "metric = \"edge_soft_f1\"\n",
    "metrics = []\n",
    "prec_recall = []\n",
    "\n",
    "\n",
    "def compute_ap(prec, rec):\n",
    "    prec, rec = np.array(prec), np.array(rec)\n",
    "    order = np.argsort(rec)\n",
    "    prec, rec = prec[order], rec[order]\n",
    "    return np.trapz(x=np.append(rec, 1), y=np.append(prec, 0))\n",
    "\n",
    "\n",
    "for exp in exps:\n",
    "    with open(exp.eval_hp_result, \"r\") as f:  # type: ignore\n",
    "        data = []\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            hp = item.pop(\"hp\")\n",
    "            data.append({**hp, **item})\n",
    "        df_eval = pd.DataFrame(data)\n",
    "        df_eval.fillna(0, inplace=True)\n",
    "    best_row = df_eval.loc[df_eval[metric].idxmax()]\n",
    "\n",
    "    with open(exp.test_hp_result, \"r\") as f:  # type: ignore\n",
    "        data = []\n",
    "        for line in f:\n",
    "            item = json.loads(line)\n",
    "            hp = item.pop(\"hp\")\n",
    "            data.append({**hp, **item})\n",
    "        df_test = pd.DataFrame(data)\n",
    "        df_test.fillna(0, inplace=True)\n",
    "\n",
    "    dist = (df_test[\"relative_percentile\"] - best_row[\"relative_percentile\"]).abs() + (\n",
    "        df_test[\"absolute_percentile\"] - best_row[\"absolute_percentile\"]\n",
    "    ).abs()\n",
    "    best_row_test = df_test.loc[dist.idxmin()]\n",
    "    display(pd.DataFrame([best_row, best_row_test]))\n",
    "\n",
    "    # for each recall level, find the best precision\n",
    "    df_sub = df_test\n",
    "\n",
    "    metrics.append(\n",
    "        {\n",
    "            \"Method\": exp.name,\n",
    "            # \"AP\": compute_ap(df_sub[\"edge_precision\"], df_sub[\"edge_recall\"]),\n",
    "            # \"Fuzzy AP\": compute_ap(\n",
    "            #     df_sub[\"fuzzy_edge_precision\"], df_sub[\"fuzzy_edge_recall\"]\n",
    "            # ),\n",
    "            # \"F1\": best_row_test[\"edge_f1\"],\n",
    "            # \"Graph similarity\": best_row_test[\"graph_similarity\"],\n",
    "            # \"Fuzzy F1\": best_row_test[\"fuzzy_edge_f1\"],\n",
    "            # \"Edge similarity\": best_row_test[\"edge_similarity\"],\n",
    "            # \"F1\": df_test[\"edge_f1\"].max(),\n",
    "            # \"Graph similarity\": df_test[\"graph_similarity\"].max(),\n",
    "            # \"Fuzzy F1\": df_test[\"fuzzy_edge_f1\"].max(),\n",
    "            # \"Edge similarity\": df_test[\"edge_similarity\"].max(),\n",
    "            # \"Edge F1\": best_row_test[\"edge_f1\"],\n",
    "            # \"Edge soft F1\": best_row_test[\"edge_soft_f1\"],\n",
    "            # \"Edge hard F1\": best_row_test[\"edge_hard_f1\"],\n",
    "            # \"Graph soft F1\": best_row_test[\"graph_soft_f1\"],\n",
    "            # \"Graph hard F1\": best_row_test[\"graph_hard_f1\"],\n",
    "            \"Edge F1\": df_test[\"edge_f1\"].max(),\n",
    "            \"Edge soft F1\": df_test[\"edge_soft_f1\"].max(),\n",
    "            \"Edge hard F1\": df_test[\"edge_hard_f1\"].max(),\n",
    "            \"Graph soft F1\": df_test[\"graph_soft_f1\"].max(),\n",
    "            \"Graph hard F1\": df_test[\"graph_hard_f1\"].max(),\n",
    "        }\n",
    "    )\n",
    "    # prec_recall.append(\n",
    "    #     pd.DataFrame(\n",
    "    #         {\n",
    "    #             \"prec\": df_sub[\"edge_precision\"],\n",
    "    #             \"rec\": df_sub[\"edge_recall\"],\n",
    "    #             \"fuzzy_prec\": df_sub[\"fuzzy_edge_precision\"],\n",
    "    #             \"fuzzy_rec\": df_sub[\"fuzzy_edge_recall\"],\n",
    "    #             \"Method\": exp.name,\n",
    "    #         }\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "# prec_recall = pd.concat(prec_recall)\n",
    "metrics = pd.DataFrame(metrics)\n",
    "# print(metrics.to_latex(index=False, float_format=\"%.3f\"))\n",
    "display(metrics)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(10, 6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# ax = sns.lineplot(\n",
    "#     data=prec_recall, x=\"rec\", y=\"prec\", hue=\"Method\", ax=axs[0], estimator=None\n",
    "# )\n",
    "# ax.set(xlabel=\"Recall\", ylabel=\"Precision\")\n",
    "\n",
    "# ax = sns.lineplot(\n",
    "#     data=prec_recall,\n",
    "#     x=\"fuzzy_rec\",\n",
    "#     y=\"fuzzy_prec\",\n",
    "#     hue=\"Method\",\n",
    "#     ax=axs[1],\n",
    "#     estimator=None,\n",
    "# )\n",
    "# ax.set(xlabel=\"Fuzzy Recall\", ylabel=\"Fuzzy Precision\")\n",
    "\n",
    "for key, ax in zip(\n",
    "    [\"Edge F1\", \"Edge soft F1\", \"Edge hard F1\", \"Graph soft F1\", \"Graph hard F1\"],\n",
    "    axs,\n",
    "):\n",
    "    ax = sns.barplot(data=metrics.sort_values(key), y=\"Method\", x=key, ax=ax)\n",
    "\n",
    "# ax = sns.barplot(\n",
    "#     data=metrics.sort_values(\"Graph soft F1\"),\n",
    "#     y=\"Method\",\n",
    "#     x=\"Graph similarity\",\n",
    "#     ax=axs[2],\n",
    "# )\n",
    "\n",
    "# ax = sns.barplot(\n",
    "#     data=metrics.sort_values(\"Fuzzy F1\"), y=\"Method\", x=\"Fuzzy F1\", ax=axs[3]\n",
    "# )\n",
    "\n",
    "# ax = sns.barplot(data=metrics.sort_values(\"F1\"), y=\"Method\", x=\"F1\", ax=axs[4])\n",
    "\n",
    "# ax = sns.barplot(\n",
    "#     data=metrics.sort_values(\"Edge similarity\"),\n",
    "#     y=\"Method\",\n",
    "#     x=\"Edge similarity\",\n",
    "#     ax=axs[5],\n",
    "# )\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(fig_dir / f\"evaluation_{dataset.replace('/', '_')}.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# exp = query(exp=\"finetune\", dataset=\"arxiv/v2\", reweighted=True)\n",
    "exp = query(exp=\"prompting\", dataset=\"arxiv/v2\", k_shot=0)\n",
    "# exp = query(exp=\"memorisation\", dataset=\"arxiv/v2\")\n",
    "with open(exp.test_hp_result, \"r\") as f:  # type: ignore\n",
    "    data = []\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        hp = item.pop(\"hp\")\n",
    "        data.append({**hp, **item})\n",
    "    df_test = pd.DataFrame(data)\n",
    "with open(exp.eval_hp_result, \"r\") as f:  # type: ignore\n",
    "    data = []\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        hp = item.pop(\"hp\")\n",
    "        data.append({**hp, **item})\n",
    "    df_eval = pd.DataFrame(data)\n",
    "\n",
    "# df[df[\"fuzzy_edge_f1\"].isna()]\n",
    "# df\n",
    "\n",
    "# 3d plot\n",
    "fig, axs = plt.subplots(ncols=2, subplot_kw={\"projection\": \"3d\"}, figsize=(12, 6))\n",
    "axs[0].plot_trisurf(\n",
    "    df_eval[\"absolute_percentile\"],\n",
    "    df_eval[\"relative_percentile\"],\n",
    "    df_eval[\"edge_soft_f1\"],\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "axs[0].set(\n",
    "    xlabel=\"Absolute percentile\", ylabel=\"Relative percentile\", zlabel=\"Edge soft F1\"\n",
    ")\n",
    "axs[1].plot_trisurf(\n",
    "    df_test[\"absolute_percentile\"],\n",
    "    df_test[\"relative_percentile\"],\n",
    "    df_test[\"edge_soft_f1\"],\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "axs[1].set(\n",
    "    xlabel=\"Absolute percentile\", ylabel=\"Relative percentile\", zlabel=\"Edge soft F1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed comparison for reweighting objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "exp_base = query(exp=\"finetune\", step=\"final\", version=1, reweighted=False)\n",
    "exp_reweighted = query(exp=\"finetune\", step=\"final\", version=3, reweighted=True)\n",
    "exp_memorised = query(exp=\"memorization\")\n",
    "assert exp_base.eval_ground_truth == exp_reweighted.eval_ground_truth\n",
    "assert exp_base.train_input == exp_reweighted.train_input\n",
    "\n",
    "G_train = load_graph(exp_base.train_input)\n",
    "G_true = load_graph(exp_base.test_ground_truth)\n",
    "G_base = load_graph(exp_base.test_output)\n",
    "G_reweighted = load_graph(exp_reweighted.test_output)\n",
    "G_memorised = load_graph(exp_memorised.test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "G_base_edges = {\n",
    "    (G_base.nodes[u][\"title\"], G_base.nodes[v][\"title\"]) for u, v in G_base.edges()\n",
    "}\n",
    "G_reweighted_edges = {\n",
    "    (G_reweighted.nodes[u][\"title\"], G_reweighted.nodes[v][\"title\"])\n",
    "    for u, v in G_reweighted.edges()\n",
    "}\n",
    "\n",
    "node_distances = nx.single_source_shortest_path_length(G_true, G_true.graph[\"root\"])\n",
    "true_edges_by_dist = defaultdict(set)\n",
    "for u, v in G_true.edges:\n",
    "    true_edges_by_dist[node_distances[u]].add(\n",
    "        (G_true.nodes[u][\"title\"], G_true.nodes[v][\"title\"])\n",
    "    )\n",
    "\n",
    "base_total_weight = sum(G_base.edges[u, v][\"weight\"] for u, v in G_base_edges)\n",
    "reweighted_total_weight = sum(\n",
    "    G_reweighted.edges[u, v][\"weight\"] for u, v in G_reweighted_edges\n",
    ")\n",
    "memorised_total_weight = sum(\n",
    "    G_memorised.edges[u, v][\"weight\"] for u, v in G_memorised.edges\n",
    ")\n",
    "\n",
    "data = []\n",
    "\n",
    "in_domain_edges = {\n",
    "    (G_true.nodes[u][\"title\"], G_true.nodes[v][\"title\"])\n",
    "    for u, v in G_true.edges() & G_train.edges()\n",
    "}\n",
    "out_of_domain_edges = {\n",
    "    (G_true.nodes[u][\"title\"], G_true.nodes[v][\"title\"])\n",
    "    for u, v in G_true.edges() - G_train.edges()\n",
    "}\n",
    "for d, edges in true_edges_by_dist.items():\n",
    "    for method, G, domain, domain_edges, total_weight in [\n",
    "        (\"base\", G_base, \"in\", in_domain_edges, base_total_weight),\n",
    "        (\"base\", G_base, \"out\", out_of_domain_edges, base_total_weight),\n",
    "        (\"reweighted\", G_reweighted, \"in\", in_domain_edges, reweighted_total_weight),\n",
    "        (\n",
    "            \"reweighted\",\n",
    "            G_reweighted,\n",
    "            \"out\",\n",
    "            out_of_domain_edges,\n",
    "            reweighted_total_weight,\n",
    "        ),\n",
    "        (\"memorised\", G_memorised, \"in\", in_domain_edges, memorised_total_weight),\n",
    "        (\"memorised\", G_memorised, \"out\", out_of_domain_edges, memorised_total_weight),\n",
    "    ]:\n",
    "        domain_edges = edges & domain_edges & G.edges()\n",
    "        for edge in domain_edges:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"level\": d,\n",
    "                    \"method\": method,\n",
    "                    \"weight\": G.edges[edge][\"weight\"] / total_weight,\n",
    "                    \"domain\": domain,\n",
    "                }\n",
    "            )\n",
    "\n",
    "df_test = pd.DataFrame(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "sns.lineplot(data=df_test, x=\"level\", y=\"weight\", hue=\"method\", style=\"domain\", ax=ax)\n",
    "ax.set(\n",
    "    yscale=\"log\",\n",
    "    xticks=np.arange(max(node_distances.values()) + 1),\n",
    "    xlabel=\"Distance from root\",\n",
    "    ylabel=\"Edge weights\",\n",
    ")\n",
    "ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(fig_dir / \"finetune_reweighted_edge_weights.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-ol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
