{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unset OMP_NUM_THREADS\n",
    "import os\n",
    "\n",
    "if \"OMP_NUM_THREADS\" in os.environ:\n",
    "    del os.environ[\"OMP_NUM_THREADS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import networkx as nx\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import graph_tool.all as gt\n",
    "\n",
    "from llm_ol.dataset import data_model\n",
    "from llm_ol.dataset.wikipedia import ROOT_CATEGORY_ID\n",
    "from llm_ol.utils.nx_to_gt import nx_to_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import Client\n",
    "\n",
    "client = Client(\n",
    "    api_key=\"none\",\n",
    "    base_url=\"http://localhost:8080/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "from llm_ol.experiments.llm.templates import RESPONSE_REGEX\n",
    "from llm_ol.experiments.llm.prompting.create_hierarchy_v2 import template\n",
    "\n",
    "prompt = template.render(\n",
    "    title=\"Single whip law\",\n",
    "    abstract=\"\"\"The Single whip law or the \"Single whip reform\" (simplified Chinese: 一条鞭法; traditional Chinese: 一條鞭法; pinyin: Yì Tiáo Biān Fǎ) was a fiscal law first instituted during the middle Ming dynasty, in the early 16th century, and then promulgated throughout the empire in 1580 by Zhang Juzheng.[1]\n",
    "The measure aimed primarily to simplify the complex fiscal code under Ming law, by commuting most obligations towards the central government — from land and poll taxes to the labour obligations of the peasantry and the tributes of prefectural and county officials — into a single silver payment, at a level based on the population and cultivated land in each prefecture. Therefore, by reducing complexity, the Single Whip law reduced the costs of tax collection, while also increasing the tax base. \"\"\",\n",
    "    examples=[\n",
    "        {\n",
    "            \"title\": \"Stoning\",\n",
    "            \"abstract\": \"\"\"Stoning, or lapidation, is a method of capital punishment where a group throws stones at a person until the subject dies from blunt trauma. It has been attested as a form of punishment for grave misdeeds since ancient history.\n",
    "The Torah and Talmud prescribe stoning as punishment for a number of offenses. Over the centuries, Rabbinic Judaism developed a number of procedural constraints which made these laws practically unenforceable. Although stoning is not mentioned in the Quran, classical Islamic jurisprudence (fiqh) imposed stoning as a hadd (sharia-prescribed) punishment for certain forms of zina (illicit sexual intercourse) on the basis of hadith (sayings and actions attributed to the Islamic prophet Muhammad). It also developed a number of procedural requirements which made zina difficult to prove in practice.\"\"\",\n",
    "            \"paths\": [\n",
    "                [\n",
    "                    \"Main topic classifications\",\n",
    "                    \"Human behavior\",\n",
    "                    \"Abuse\",\n",
    "                    \"Cruelty\",\n",
    "                    \"Torture\",\n",
    "                ],\n",
    "                [\"Main topic classifications\", \"Human behavior\", \"Violence\", \"Torture\"],\n",
    "                [\n",
    "                    \"Main topic classifications\",\n",
    "                    \"Law\",\n",
    "                    \"Law-related events\",\n",
    "                    \"Crimes\",\n",
    "                    \"Torture\",\n",
    "                ],\n",
    "                [\n",
    "                    \"Main topic classifications\",\n",
    "                    \"Law\",\n",
    "                    \"Legal aspects of death\",\n",
    "                    \"Killings by type\",\n",
    "                ],\n",
    "                [\"Main topic classifications\", \"Society\", \"Violence\", \"Torture\"],\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# print(\"\\n\".join(textwrap.wrap(prompt, width=100, replace_whitespace=False)))\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": prompt,\n",
    "#         }\n",
    "#     ],\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     # extra_body={\"guided_regex\": RESPONSE_REGEX},\n",
    "#     temperature=0,\n",
    "#     max_tokens=128,\n",
    "# )\n",
    "# out = completion.choices[0].message.content\n",
    "# print(out)\n",
    "# print(re.fullmatch(RESPONSE_REGEX, out).group(0))\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    extra_body={\"guided_regex\": RESPONSE_REGEX},\n",
    "    temperature=0.1,\n",
    "    max_tokens=256,\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = data_model.load_graph(\"out/data/wikipedia/v2/full/graph_depth_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {}\n",
    "for node, data in G.nodes(data=True):\n",
    "    for page in data[\"pages\"]:\n",
    "        if page[\"id\"] not in items:\n",
    "            items[page[\"id\"]] = {**page, \"categories\": [node]}\n",
    "        else:\n",
    "            items[page[\"id\"]][\"categories\"].append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from llm_ol.experiments.prompting.create_hierarchy import create_hierarchy\n",
    "\n",
    "item = random.choice(list(items.values()))\n",
    "out = lm + create_hierarchy(item[\"title\"], item[\"abstract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set()\n",
    "\n",
    "result = []\n",
    "\n",
    "for _ in range(3):\n",
    "    item = random.choice(items)\n",
    "    out = lm + categorise_article_top_down(\n",
    "        item[\"title\"], item[\"abstract\"], list(categories)\n",
    "    )\n",
    "    categories.update(out[\"cats\"])\n",
    "    result.append((item, out[\"cats\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"out/experiments/prompting/dev/categoried_pages.jsonl\") as f:\n",
    "    results = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "categories = defaultdict(list)\n",
    "for page in results:\n",
    "    for cat in page[\"categories\"]:\n",
    "        categories[cat].append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(v) for v in categories.values()], bins=20, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import guidance\n",
    "\n",
    "item = random.choice(list(items.values()))\n",
    "print(item)\n",
    "\n",
    "s = \"\"\"The following is an article's title and abstract. Your task is to assign this article to suitable category hierarchy. \\\n",
    "A category is typically represented by a word or a short phrase, representing broader topics/concepts that the article is about. \\\n",
    "A category hierarchy is a directed acyclic graph that starts with a detailed categorisation and becomes more and more \\\n",
    "general higher up the hierarchy, until it reaches the special base category \"Main topic classification\".\n",
    "\n",
    "An example hierarchy for an article on \"Single whip law\" might be have the following category hierarchy:\n",
    "\n",
    "```txt\n",
    "Main topic classifications -> Economy -> Economic history -> History of taxation\n",
    "Main topic classifications -> Law -> Law by issue -> Legal history by issue -> History of taxation\n",
    "Main topic classifications -> Law -> Law by issue -> Tax law\n",
    "Main topic classifications -> Law -> Law stubs -> Asian law stubs\n",
    "Main topic classifications -> Politics -> Political history -> History of taxation\n",
    "```\n",
    "\n",
    "Another example hierarchy for an article on \"Stoning\" is:\n",
    "\n",
    "```txt\n",
    "Main topic classifications -> Human behavior -> Abuse -> Cruelty -> Torture\n",
    "Main topic classifications -> Human behavior -> Violence -> Torture\n",
    "Main topic classifications -> Law -> Law-related events -> Crimes -> Torture\n",
    "Main topic classifications -> Law -> Legal aspects of death -> Killings by type\n",
    "Main topic classifications -> Society -> Violence -> Torture\n",
    "```\"\"\" + \"\"\"\n",
    "\n",
    "Title: {title}\n",
    "{abstract}\n",
    "\n",
    "Provide a category hierarchy for the above article. Use the same format as the examples above.\n",
    "\"\"\".format(\n",
    "    **item\n",
    ")\n",
    "\n",
    "with guidance.instruction():\n",
    "    out = lm + s\n",
    "out += \"```txt\\n\"\n",
    "out += guidance.gen(name=\"hierarchy\", max_tokens=500, stop=\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results = []\n",
    "with open(\"out/experiments/prompting/dev-h/categoried_pages.jsonl\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        try:\n",
    "            item[\"hierarchy\"] = json.loads(item[\"hierarchy\"])\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to parse hierarchy for {item['title']}\")\n",
    "            item[\"hierarchy\"] = None\n",
    "        results.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "\n",
    "def walk_hierarchy(hierarchy: dict):\n",
    "    for parent, sub_hierarchy in hierarchy.items():\n",
    "        if sub_hierarchy == \"LEAF\":\n",
    "            continue\n",
    "        elif isinstance(sub_hierarchy, dict):\n",
    "            for child in sub_hierarchy:\n",
    "                G.add_edge(parent, child)\n",
    "            walk_hierarchy(sub_hierarchy)\n",
    "        else:\n",
    "            print(f\"Unknown type {parent} -> {sub_hierarchy}\")\n",
    "\n",
    "\n",
    "for item in results:\n",
    "    if item[\"hierarchy\"] is not None:\n",
    "        walk_hierarchy(item[\"hierarchy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# show random subgraphs\n",
    "random_root = random.choice(list(G.nodes))\n",
    "while not (5 < len(random_subgraph := nx.ego_graph(G, random_root, radius=2)) < 30):\n",
    "    random_root = random.choice(list(G.nodes))\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# nx.draw_networkx(random_subgraph, with_labels=True, ax=ax, pos=nx.circular_layout(random_subgraph))\n",
    "# ax.set(title=f\"Random subgraph of {random_root}\")\n",
    "\n",
    "print(random_root)\n",
    "A = nx.drawing.nx_agraph.to_agraph(random_subgraph)\n",
    "A.layout(\"fdp\")\n",
    "A.draw(f\"out/experiments/prompting/dev-h/visualisation/{random_root}.png\")\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_leaf = random.choice(list(G.nodes))\n",
    "print(G.nodes[random_leaf][\"title\"])\n",
    "\n",
    "i = 0\n",
    "for path in nx.shortest_simple_paths(G, ROOT_CATEGORY_ID, random_leaf):\n",
    "    names = [G.nodes[node][\"title\"] for node in path]\n",
    "    print(\" -> \".join(names))\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy(node, n: int):\n",
    "    paths = []\n",
    "    G_sub = nx.DiGraph()\n",
    "    i = 0\n",
    "    for path in nx.shortest_simple_paths(G, ROOT_CATEGORY_ID, node):\n",
    "        names = [G.nodes[node][\"title\"] for node in path]\n",
    "        paths.append(names)\n",
    "        for parent, child in zip(names[:-1], names[1:]):\n",
    "            G_sub.add_edge(parent, child)\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_root(G_gt: gt.Graph, nx_to_gt_map, gt_to_nx_map, page, cutoff=None):\n",
    "    page_node = G_gt.add_vertex()\n",
    "    for category in page[\"categories\"]:\n",
    "        G_gt.add_edge(nx_to_gt_map[category], page_node)\n",
    "\n",
    "    try:\n",
    "        paths = []\n",
    "        for i, path in enumerate(\n",
    "            # nx.all_simple_paths(G, ROOT_CATEGORY_ID, page[\"id\"], cutoff=cutoff)\n",
    "            gt.all_paths(\n",
    "                G_gt,\n",
    "                source=nx_to_gt_map[ROOT_CATEGORY_ID],\n",
    "                target=page_node,\n",
    "                cutoff=cutoff,\n",
    "            )\n",
    "        ):\n",
    "            names = tuple(G.nodes[gt_to_nx_map[node]][\"title\"] for node in path[:-1])\n",
    "            paths.append(names)\n",
    "    finally:\n",
    "        G_gt.remove_vertex(page_node)\n",
    "\n",
    "    random.shuffle(paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_gt, nx_to_gt_map, gt_to_nx_map = nx_to_gt(G)\n",
    "\n",
    "item = random.choice(list(items.values()))\n",
    "print(item[\"title\"])\n",
    "for path in paths_to_root(G_gt, nx_to_gt_map, gt_to_nx_map, item, cutoff=3):\n",
    "    print(\" -> \".join(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_gt, nx_to_gt_map, gt_to_nx_map = nx_to_gt(G)\n",
    "n = len(items)\n",
    "results = []\n",
    "\n",
    "print(f\"Sample {n}/{len(items)} items\")\n",
    "for item in tqdm(random.sample(list(items.values()), n)):\n",
    "    results.append(paths_to_root(G_gt, nx_to_gt_map, gt_to_nx_map, item, cutoff=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(results):\n",
    "    all_edges = G.edges()\n",
    "    all_edges = {(G.nodes[u][\"title\"], G.nodes[v][\"title\"]) for u, v in all_edges}\n",
    "\n",
    "    for paths in results:\n",
    "        for path in paths:\n",
    "            for parent, child in zip(path[:-1], path[1:]):\n",
    "                all_edges.discard((parent, child))\n",
    "\n",
    "    return 1 - len(all_edges) / len(G.edges())\n",
    "\n",
    "\n",
    "coverage(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "sns.histplot(\n",
    "    [len(ps) for ps in results], bins=10, log_scale=True, ax=ax1, stat=\"density\"\n",
    ")\n",
    "ax1.set(xlabel=\"Number of paths\")\n",
    "sns.histplot(\n",
    "    [len(p) for ps in results for p in ps], discrete=True, ax=ax2, stat=\"density\"\n",
    ")\n",
    "ax2.set(xlabel=\"Path length\")\n",
    "\n",
    "xs = np.linspace(1, len(results), 11, dtype=int)\n",
    "sns.lineplot(x=xs, y=[coverage(results[:i]) for i in xs], ax=ax3, marker=\"o\")\n",
    "ax3.set(xlabel=\"Number of samples\", ylabel=\"Coverage\", ylim=(0, 1))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"out/graphs/cutoff_5_depth_3_n_paths.png\", dpi=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = G.edges()\n",
    "not_covered = {(G.nodes[u][\"title\"], G.nodes[v][\"title\"]) for u, v in all_edges}\n",
    "for paths in results:\n",
    "    for path in paths:\n",
    "        for parent, child in zip(path[:-1], path[1:]):\n",
    "            not_covered.discard((parent, child))\n",
    "\n",
    "not_covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = data_model.load_graph(\"out/data/wikipedia/v2/train_test_split/train_graph.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = 31686682\n",
    "\n",
    "path = nx.shortest_path(G, G.graph[\"root\"], id_)\n",
    "[G.nodes[node][\"title\"] for node in path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_test = nx.empty_graph(3)\n",
    "\n",
    "nx.multi_source_dijkstra_path_length(G_test, {0, 1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
