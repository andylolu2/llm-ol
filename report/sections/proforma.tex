\begin{sffamily} % use a sans-serif font for the pro-forma cover sheet

    \begin{titlepage}
        \makeatletter

        % University logo with shield hanging in left margin
        \hspace*{-14mm}\includegraphics[width=65mm]{logo-dcst-colour.pdf}

        \ifsubmission

            % submission proforma cover page for blind marking
            \begin{Large}
                \vspace{20mm}
                Research project report title page

                \vspace{35mm}
                Candidate \candidatenumber

                \vspace{42mm}
                \textsl{``\@title''}

            \end{Large}

        \else

            % regular cover page
            \begin{center}
                \Huge
                \vspace{\fill}

                \@title
                \vspace{\fill}

                \@author
                \vspace{10mm}

                \Large
                \college
                \vspace{\fill}

                \@date
                \vspace{\fill}

            \end{center}

        \fi

        \vspace{\fill}
        \begin{center}
            Submitted in partial fulfillment of the requirements for the\\
            \course
        \end{center}

        \makeatother
    \end{titlepage}

    \newpage

    Total page count: \pageref{lastpage}

    % calculate number of pages from
    % \label{firstcontentpage} to \label{lastcontentpage} inclusive
    \makeatletter
    \@tempcnta=\getpagerefnumber{lastcontentpage}\relax%
    \advance\@tempcnta by -\getpagerefnumber{firstcontentpage}%
    \advance\@tempcnta by 1%
    \xdef\contentpages{\the\@tempcnta}%
    \makeatother

    Main chapters (excluding front-matter, references and appendix):
    \contentpages~pages
    (pp~\pageref{firstcontentpage}--\pageref{lastcontentpage})

    Main chapters word count: 10000\footnote{Computed with \texttt{texcount}.}

\end{sffamily}

\vspace{\fill}
\onehalfspacing
\makeatletter
\textbf{\Huge Declaration}
\vspace{40pt}

\ifsubmission
    I, [Blind candidate number], being a candidate for Part III of the Computer Science Tripos, hereby declare that this project report and the work described in it are my own work, unaided except as may be specified below, and that the project report does not contain material that has already been used to any substantial extent for a comparable purpose. The project required the use of AI-assisted platform GitHub Copilot in chapter 3 and 4, and such use is acknowledged in the text. I am content for my project report to be made available to the students and staff of the University.

    \bigskip
    \textbf{Date:} \today
\else
    I, \@author\ of \college, being a candidate for Part III of the Computer Science Tripos, hereby declare that this project report and the work described in it are my own work, unaided except as may be specified below, and that the project report does not contain material that has already been used to any substantial extent for a comparable purpose. The project required the use of AI-assisted platform GitHub Copilot in chapter 3 and 4, and such use is acknowledged in the text. I am content for my project report to be made available to the students and staff of the University.

    \bigskip
    \textbf{Signed:} \@author

    \bigskip
    \textbf{Date:} \today
\fi
\vspace{\fill}
\makeatother

\chapter*{Abstract}

Ontologies are useful for automatic machine processing as they represent knowledge in a structured format. Yet, constructing ontologies requires substantial manual effort. To automate part of this process, large language models (LLMs) have been applied to solve various subtasks of ontology learning. However, this partial ontology learning does not capture the interactions between subtasks.
We address this gap by introducing \name, a general and scalable method for solving the \emph{full} task of building an ontology from scratch.
Rather than focusing on subtasks, like individual relations between entities, we model entire subcomponents of the target ontology by finetuning an LLM with a custom regulariser that reduces overfitting on high-frequency concepts. We introduce a novel suite of metrics for evaluating the quality of the generated ontology by measuring its semantic and structural similarity to the ground truth. Our metrics stem from modern deep learning evaluation techniques, but make fewer assumptions about the ontologies than standard ontology metrics.
Our results on Wikipedia show that \name outperforms subtask composition methods, producing more semantically accurate ontologies while maintaining structural integrity. We further demonstrate that our model can be effectively adapted to a new domain, like arXiv, needing only a small number of training examples.

\ifsubmission\else
    % not included in submission for blind marking:

    \chapter*{Acknowledgements}

    This project would not have been possible without the wonderful
    support of \ldots [optional]

\fi
\cleardoublepage % preserve page numbers after missing acknowledgements