\chapter{Background}

This project's research topic is in the intersection of ontology learning, ontology evaluation, and large language models for structured knowledge representation. Part of the contribution of this project is an original framework to study ontology learning in an end-to-end manner. In \cref{sec:what-is-an-ontology,sec:ontology-learning}, we give a precise definition of end-to-end ontology learning and provide an overview of related works. We discuss the deficiencies of prior efforts and the research gaps that this project aims to address. In \cref{sec:evaluating-ontologies}, we discuss the standard techniques for evaluating the quality of generated ontologies and the limitations of these techniques. Finally in \cref{sec:graph,sec:LLMs-for-knowledge-representationl}, we also introduce the necessary background for understanding our methods in \cref{chap:implementation,chap:evaluation}.

\section{What is an ontology?}  \label{sec:what-is-an-ontology}

% [What is an ontology and how is it represented?]
An ontology is a structured way of representing concepts and relations of a shared conceptualisation, i.e. domain knowledge \cite{gruber1995toward,gruber1993translation}. The primary goal of an ontology is to represent the entities in a domain in a machine-readable format and link the relationships among them \cite{national2022ontologies}. This project focuses on ontologies that only consist of concepts and taxonomic relations which represent \emph{is-a} or \emph{is-subclass-of} relationships between concepts. In some cases, the \emph{is-part-of} relation is also considered a taxonomic relation.

% [Representations of ontologies]
We treat such an ontology as a rooted labelled directed graph where nodes represent concepts, edges represent taxonomic relations and the root node is the special concept of all concepts. Formally, we define an ontology as $\O = (\V, \E, r)$ where $\V$ is the set of concepts, $\E \subseteq \V \times \V$ is the set of taxonomic relations, and $r \in \V$ is the root concept. A strict ontology asserts that the taxonomic relation is asymmetric thus the graph must be acyclic, though in practice some ontologies, such as the Wikipedia ontology studied in this project, may contain cycles. We therefore do not assume that an ontology graph is necessarily acyclic. Examples of widely used ontologies include WordNet \cite{miller1995wordnet} with 117,659 concepts and 89,089 taxonomic relations and the Gene Ontology \cite{ashburner2000gene} with 42,255 concepts and 66,810 taxonomic relations.

\section{Ontology learning}  \label{sec:ontology-learning}

% [What is the precise task we study in this paper?]
Ontology learning is the automatic extraction of ontological elements \cite{hazman2011survey}. The most studied source of input is unstructured text, though there are also works on OL on semi-structured data like HTML \cite{karoui2004ontology}. In this project, the input is a set of documents $\D$, each consisting of a title and some unstructured main body text. We additionally assume each document $d \in \D$ is annotated to be associated with one or more concepts in the ground truth ontology $\V_{d} \subseteq \V$ which we utilise for training (but not required for inference). For example, the Wikipedia page on ``Natural number'' is annotated with concepts ``Cardinal numbers'' and ``Number theory''. The task is to reconstruct the ground truth ontology $\O$ given the set of documents $\D$. We name this task \emph{end-to-end ontology learning}. In this section, we give an overview of prior works in OL and discuss the research gaps that this project aims to address.

\subsection{Subtask composition}

Prior works view OL as a composition of subtasks, and study each subtask in isolation~\cite{buitelaar2005ontology,asim2018survey}. A typical pipeline for building a simple ontology is to first perform concept discovery (identify $\V$), and then relation extraction (identify $\E$)~\cite{cimiano2005text2onto,kaushik2018automatic}. A notable approach for relation extraction is Hearst patterns~\cite{hearst1998automated}. Hearst patterns are hand-crafted lexico-syntactic patterns that exploit natural language structure to discover taxonomic relations. For example, the pattern ``[noun phrase] such as [noun phrase]'' matches phrases like ``dogs such as chihuahuas'', and thus can be processed by regular expressions to identify the relation ``dog $\to$ chihuahua''. Hearst patterns suffer from low recall, as the relations must occur in exact configurations to be identified by the rules. \citet{roller2018hearst} suggests smoothing techniques to alleviate this issue though at the cost of lower precision. Another approach for relation extraction utilises word co-occurrence statistics in sentences or documents to predict taxonomic relations \cite{cimiano2005learning}. Recently, language models have been used for OL. REBEL~\cite{cabot2021rebel} treats relation discovery as a translation task, and finetunes encoder-decoder LLMs to extract both taxonomic and non-taxonomic relations. \citet{babaei2023llms4ol} benchmarked a wide family of LLMs for concept and relation discovery, and showed promising results.

While studying subtasks permits fine-grained analysis and evaluation, it lacks several components to be a complete solution. From an applied perspective, many proposed methods do not produce an explicit output. For example, some relation extraction methods only produce a global ranking of potential relations \cite{roller2018hearst} without specifying a concrete method for deciding which relations to include in the final ontology. Extra steps are required (e.g., choosing an appropriate threshold) to convert the predictions into a concrete output. From an evaluation perspective, studying subtasks does not directly indicate the subsequent impact on the quality of the final ontology. For example, a small error in concept discovery may lead to a significant degradation in the final ontology quality due to accumulated error propagation. Such indirect effects cannot be captured by studying subtasks in isolation. This project aims to close these gaps by developing methods that produce ontologies explicitly and evaluate the final ontology quality directly.

\subsection{Description Logic}

Another approach to OL is that by Description Logic (DL). On a high-level, DL is a collection of first-order logic formulae with concept descriptions as atoms for representing knowledge in a structured, symbolic way \cite{baader2017introduction}. For example, the knowledge ``a bee is an insect that produces honey'' can be expressed in DL as
    {
        \sffamily
        $\text{Bee} \sqsubseteq \text{Insect} \sqcap  \exists \text{produces}. \text{Honey}$
    }.
The advantage of using DL to represent ontologies is that it is more expressive, in comparison to graph-based representations. One can easily express rules relating multiple concepts and relations while there is no direct analogue in graphs. Core works in building DL-based ontologies viewed OL as a translation task from natural language to DL formulae \citet{petrucci2016ontology,petrucci2018expressive} and trained sequence-to-sequence neural networks to perform this task. However, due to the lack of annotated datasets, the authors only evaluated their method on synthetic datasets and a small number of manually curated examples. The lack of large-scale evaluation and annotated data in the real world makes it unclear whether such methods can scale to solve practical problems. This project takes a more pragmatic approach by focusing on graph-based representations which have more annotated data available and are thus more accessible in practice.

\subsection{End-to-end ontology learning}

While end-to-end OL has not been studied extensively, there are proof-of-concept works that have considered the problem. \citet{funk2023towards} proposes to build an ontology from scratch by recursively prompting LLMs: Given a seed concept, the authors prompt pretrained LLMs to list possible child concepts and recurse on each new concept until some stopping criterion is met. Another approach by \citet{trajanoska2023enhancing} prompts a pretrained LLM to generate the entire ontology in one completion. However, both studies are limited in both the scale of the task and evaluation: they only considered ontologies of up to 1000 concepts and relied on manual, qualitative evaluation. We bridge this gap by proposing a method that can scale to practical problem sizes and new metrics for systematic qualitative evaluation.

\section{Evaluating ontologies}  \label{sec:evaluating-ontologies}

% [Prior approaches to evaluating OL.]
The evaluation of ontologies is an open research area. The main approaches are gold standard evaluation~\cite{Zavitsanos2011GoldSE}, which matches elements of the generated ontology with a predefined target ontology; task-based evaluation~\cite{porzel2004task}, which measures the usefulness of the ontology on a specific application; and human evaluation \cite{raad2015survey,brank2005survey}. In this project, we evaluate by the gold standard metric as it is the most straightforward approach when ground-truth ontology exists.

To compare a generated ontology with the ground truth, prior works have considered matching concepts~\cite{maedche2002measuring} and direct or indirect relations~\cite{Kashyap2005TaxaMinerAE} by literal text comparison. A straightforward metric is the precision and recall of the relations:
\[
    P = \frac{|\E \cap \E'|}{|\E'|}, \quad R = \frac{|\E \cap \E'|}{|\E|}
\]
where $\O = (\V, \E, r)$ and $\O' = (\V', \E', r')$ are the ground truth and generated ontologies respectively. However, this approach is unreliable as it is sensitive to minor differences in the text representation of the concepts, such as casing or pluralisation. To reduce sensitivity to syntactic differences, others have also considered edit-distance~\cite{Ehrig2005SimilarityFO}.

However, one is typically interested in whether the generated ontology is semantically similar to the ground truth, rather than syntactically. \citet{Zavitsanos2011GoldSE} relies on detailed descriptions for each concept and measures semantic similarity by comparing the word distribution in the descriptions of two concepts. Others have also considered mapping two concepts to a third reference ontology like WordNet~\cite{maedche2002measuring} and measuring similarity by the distance between the two concepts in the reference graph \cite{Treeratpituk2013GraphbasedAT}. This, however, requires the reference ontology to have a high coverage of the concepts as it cannot handle out-of-vocabulary concepts. These techniques for measuring semantic similarity may be considered unreliable and have been superseded by current methods~\cite{conneau2017supervised}. We instead rely on more modern techniques like pretrained text embedders \cite{devlin2018bert} and graph convolutions \cite{kipf2016semi} to match substructures between the two ontologies.

\section{LLMs for knowledge representation}  \label{sec:LLMs-for-knowledge-representationl}

Outside of OL, there is a growing body of research on using LLMs to construct structured knowledge representations, most commonly as \emph{knowledge graphs} (KGs) \cite{singhal2012introducing}. While ontologies focus on capturing the relationship between concepts, KGs aim to represent \emph{instances} of such concepts and their properties \cite{guarino1995ontologies}. For example, an ontology may capture the common sense relation that ``a person is born at a place'', while a knowledge graph might contain explicit instantiations like ``Barack Obama is born in Honolulu''. As a result, the construction of KGs focuses more on extracting facts from the source corpus and less on the structure of the graph itself.

Similar to OL, knowledge graph construction is rarely studied in an end-to-end framework. Instead, most works focus on subtasks such as entity prediction \cite{lin2015modeling,xie2016representation}: discover which entities should be in the KG; link prediction \cite{liben2003link,trouillon2016complex}: classify whether two entities are related; and triplet classification \cite{lin2015learning,wang2014knowledge}: given a head node, a relation, and a tail node, predict whether the head and tail nodes are connected by the specified relation. The first work to use LLMs for KG completion is \citet{petroni2019language}, who demonstrates that many facts can be elicited by simply prompting an LLM with a relation and a head entity. Recent works have further explored the use of LLMs for KG construction, such as \citet{yao2023exploring} who finetuned LLMs for link prediction and relation prediction, and \citet{wang2020language} who inspected the attention patterns of LLMs to extract the relation token(s) between two entities in the source text. While these works have shown promising results, they do not address the research questions of this project, in particular, whether there are any benefits to studying knowledge representation tasks in an end-to-end manner. While the primary focus of this project is OL, the results have extended implications for KG construction as well.

\section{Graph analysis}  \label{sec:graph}

Since we treat ontologies as graphs in this project, standard graph analysis techniques are applicable too. In particular, these ideas will become relevant when we design metrics for analysing and evaluating the generated ontologies. This section explains two key concepts used in this project: \emph{network motifs} and \emph{node embeddings}.

\subsection{Network motifs}  \label{sec:network-motifs}

Network motifs are recurring subgraphs that appear more frequently in a graph than in a random graph \cite{milo2002network}. Studying the frequency or the location of the motifs in a graph can provide insights into the graph's global structures. For example, the fully connected three-vertex graph is a motif commonly found in social networks \cite{stone2019network}, indicating the general property that if Alice is friends with Bob and Bob is friends with Charlie, then Alice and Charlie are likely to be friends as well. More generally, motif analysis is an instantiation of \emph{graphlet counting} \cite{ribeiro2021survey} which aims to compute the frequency of all possible subgraphs of a certain size. Graphlet counting has been used to evaluate graph generation models \cite{you2018graphrnn} by comparing the $n$-node graphlet counts between two graph distributions. In this project, however, we are interested in comparing two specific graph instances (the generated ontology versus the ground truth) hence such metrics do not directly apply.

\subsection{Node embeddings}  \label{sec:node-embeddings}

Node embeddings are vector representations of the nodes in a graph that aim to summarise their graph position and the structure of their local graph neighbourhood \cite{hamilton2020graph}. Node embeddings are useful for many graph analysis tasks, such as node classification and link prediction. One of the most popular algorithms for generating node embeddings is node2vec \cite{grover2016node2vec}, which uses random walks to sample the relevant neighbourhood around each node and optimises the embeddings to be predictive of whether two nodes are neighbours. It is, however, only designed for graphs where nodes are unlabelled (also known as homogenous graphs) and thus not suitable for ontologies.

A method suitable for learning node embeddings for labelled graphs is \emph{graph convolutions}. Suppose for a graph $\G = (\V, \E)$, we have $\m{A}$ its adjacency matrix and the node feature (label) matrix $\m{X} \in \R^{|V| \times d}$, where $d$ is the feature dimension. The graph convolution operator with parameters $\m{W} \in \R^{d \times d}$ is defined as
\[
    \m{X}' = \hat{\m{D}}^{-1/2} \hat{\m{A}} \hat{\m{D}}^{-1/2} \m{X} \m{W}
\]
where $\hat{\m{A}} = \m{A} + \m{I}$ and $\hat{D}_{ii} = \sum_j \hat{A}_{ij}$ the diagonal degree matrix. Intuitively, applying a graph convolution to $\m{X}$ aggregates the features of each node's 1-hop neighbourhood and applies a linear transformation to the result. A simple yet effective extension to gather information from further neighbours without introducing more parameters is known as a \emph{simple graph convolution} \cite{wu2019simplifying}:
\begin{equation}  \label{eq:simple-graph-conv}
    \m{X}' = \left(\hat{\m{D}}^{-1/2} \hat{\m{A}} \hat{\m{D}}^{-1/2}\right)^K \m{X} \m{W}
\end{equation}
where $K$ determines the number of hops. A weakness of simple graph convolutions is that they are prone to \emph{over-smoothing} \cite{zhu2020simple}, where node embeddings become increasingly generic and thus uninformative as $K \to \infty$. Empirically, using small values of $K$ (e.g. $K = 2$) tends to be the most effective \cite{wu2019simplifying}.