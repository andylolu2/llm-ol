% Main document

\begin{abstract}
    % Write an ``elevator pitch''. In other words what's the
    % problem, why is it important or interesting, and what's your approach. (100 words)
    \noindent Prior to recent progress, \gls{ol} has mostly been tackled with rule-based methods which scale poorly. Recent work by \citet{llms4ol} demonstrated potential for applying \gls{llm} to several sub-tasks of \gls{ol}. This project aims to extend this idea to build a complete system for \gls{ol} of Wikipedia by leveraging the flexibility of \gls{llm}s, bypassing the needs for specialist models and large training datasets. If successful, this approach, by the virtue of the generality of \gls{llm}s, will be applicable to corpuses other than Wikipedia with minimal re-training and modifications.
\end{abstract}

\section*{Introduction, approach and outcomes}

% Provide an introduction to your project or essay. In particular, try to motivate the work and explain the relevant context (general background, as well as sufficient detail about any related work).

% What's the basic idea and approach? What are you thinking of doing, and how is it going to solve the problem (or need) you've identified. What are you going to ``produce''? A project will typically produce one (or perhaps more) of the following: a piece of software, an evaluation of a published result, a proof, or the design (and perhaps the construction of) a new piece of hardware. An essay will typically either review and critique a particular area of the academic literature, or evaluate a published result or proof. Try to name the specific things (and describe them) in this part of the proposal -- this will allow you to refer to them in the next.

\subsection*{What is an Ontology?}

An ontology is a structured representation of widely-accepted concepts that aids automated processing. A minimal ontology is composed of \emph{classes} (concepts) and \emph{relations} (links between concepts). The basic relation is a \emph{taxonomic relation} which represents the \emph{is-a}/\emph{subclass-of} relationship\footnote{For example, \emph{chatbots} and \emph{artificial intelligence} can be classes of an ontology that are related by a \emph{subclass-of} relation.}. \gls{ol} aims to automate the process of building an ontology.

In this project, we focus on the categories of Wikipedia which is a simplistic ontology.\footnote{Other notable examples of ontologies include Gene Ontology \citep{gene-ontology} and Unified Medical Language System \citep{umls}.} The standard format to encode ontologies is by \gls{owl} which we will use for the datasets constructed in this project.

\subsection*{Motivation}

\gls{ol} is a complex process. It is typically broken down into several sub-tasks, and specialist models are employed to solve each of them individually. On the other hand, \gls{llm}s have been shown to be general problem solvers \citep{gpt3} and to encapsulate vast amount of world knowledge \citep{llm-knowledge-base}. This makes \gls{llm}s a good candidate for improving the core logic for \gls{ol} while making the process simpler (only one model required).

Prior works in this area do not evaluate the complete process of building an ontology from scratch. Instead, they focus on using \gls{llm}s for sub-tasks of \gls{ol} \citep{llms4ol} or Knowledge Graph Completion \citep{yao2023exploring,cabot2021rebel}. In many cases, solutions to such sub-tasks are insufficient by themselves to build a full \gls{ol} system and existing works often neglect the additional, non-trivial steps required to do so. For example, taxonomy discovery is often treated as a binary classification task given two classes. However, many works do not consider how such two candidate classes are sampled in practice to construct an ontology. This project aims to show that such gaps can be effectively closed by using \gls{llm}s for \gls{ol}.

\subsection*{Research questions}

This project aims to answer: \emph{How can we use \gls{llm}s for \gls{ol}?} We plan to do so by:
\begin{enumerate}
    \item Proposing a system for \gls{ol} where \gls{llm}s plays a central role; and
    \item Demonstrating the system's effectiveness by comparing against existing methods.
\end{enumerate}

Extensions of the project might focus on:
\begin{itemize}
    \item Can downstream tasks benefit from the resultant ontology?
    \item Can we use \gls{llm}s to discover other components of an ontology?
    \item How do \gls{llm}s perform \gls{ol}? For example, do the embeddings/internal activations already form the structure of the ontology?
\end{itemize}


\subsection*{Methodology}

\subsubsection*{Implementation}

By leveraging the generative nature of \gls{llm}s, we propose a method that performs \emph{class discovery} (generating the `nodes') and \emph{taxonomy discovery} (generating the `edges') as a joint process rather than separate sub-tasks. The basic idea is to construct the ontology `bottom-up', where at each step we recursively prompt a pre-trained \gls{llm} to generate the parent for the current node until we reach the root node.

We will experiment with zero-shot prompting, few-shot prompting, and fine-tuning a \gls{llm} based on Wikipedia categories. We expect to refine the above approach throughout the project.

\subsubsection*{Evaluation}

Evaluation will be done on a hold-out set from Wikipedia categories for in-distribution validation and arXiv categories for out-of-distribution testing.

To evaluate the ontology as a whole, we can compare its similarity with the ground truth. Unfortunately, there is no standard method to compare ontologies, though there are vast amounts of literature for reference \citep{ontology-matching}. Part of the work is to choose a suitable metric. An alternative will be to evaluate base on downstream (e.g., document clustering) performance, akin to how typical unsupervised learning methods are evaluated.

To summarise, this project aims to make the following core contributions:
\begin{itemize}
    \item Construct and share a dataset for \gls{ol} based on Wikipedia and arXiv categories.
    \item Be the first to apply \gls{llm}s to build ontologies from scratch and evaluate the method's end-to-end performance.
\end{itemize}

\section*{Workplan}
% Project students have approximately 26 weeks between the approval of
% the proposal by the Head of Department, and the submission of the dissertation. This section
% should account for what you intend to do during that time. You should divide the time into two-week chunks including dates, and
% describe the work to be done (and, as relevant, milestones to be
% achieved) in each chunk. You should leave two
% chunks for writing a project dissertation. You should leave 1 chunk for contingencies.

\subsection*{Work content}

\subsubsection*{Core}
\begin{itemize}
    \item Construct the Wikipedia and arXiv categories dataset in \gls{owl} by aggregating data from the public APIs.
    \item Implement a simple baseline for reference, such as by Named Entity Recognition and Hearst patterns \citep{hearst}.
    \item Propose methods for \gls{ol} using \gls{llm}s, starting with the approach described in the previous section.
    \item Develop suitable evaluation metrics for computing ontology similarity. Evaluate the resultant ontologies for each method above.
\end{itemize}

\subsubsection*{Extensions}
\begin{itemize}
    \item Apply the learnt ontology for downstream tasks like document clustering and compare the performance against the ground truth and baseline standard (e.g., by embedding similarity).
    \item Use \gls{llm}s to discover additional components of an ontology, such as defining which classes are mutually exclusive.
    \item Inspect the internals of \gls{llm}s and probe for structures resembling an ontology. (e.g., are the internal representations for the categories hierarchically structured?)
\end{itemize}

\subsubsection*{Backup plan}
The most risky part of this project is the proposed novel approach to \gls{ol} (doing class and taxonomy discovery jointly). The backup plan is to revert to the standard approach of solving the sub-tasks independently. This is the safer option since \citet{llms4ol} have already shown promising results for the two sub-tasks.

\subsection*{Success criteria}

We aim to demonstrate the success of the project by:
\begin{enumerate}
    \item Publicly sharing the constructed datasets based on Wikipedia categories and arXiv categories.
    \item Producing higher-quality ontologies than the baseline methods according to our evaluation metrics.
\end{enumerate}

\subsection*{Timeline}

\subsubsection*{Christmas}
\textbf{Week 1-2} (04/12-18/12) \hfill \textbf{Risk: Low}
\begin{itemize}
    \item Setup access to compute resources (Lab GPUs \& HPC).
    \item Construct the Wikipedia categories and arXiv categories datasets in \gls{owl} format.
    \item \textbf{Milestone}: Constructed train, evaluation and test dataset.
\end{itemize}

\textbf{Week 3-4} (18/12-01/01) \hfill \textbf{Risk: Low}
\begin{itemize}
    \item Implement the NER + Hearst pattern baseline.
    \item Implement an (initial) evaluation metric for comparing ontologies. More reading is likely required.
    \item Evaluate the baseline with the metric.
    \item \textbf{Milestone}: Established baseline.
\end{itemize}

\textbf{Week 5-6} (01/01-15/01)
\begin{itemize}
    \item Reserved time for holiday and other course works.
\end{itemize}

\subsubsection*{Lent}
\textbf{Week 1-2} (15/01-29/01) \hfill \textbf{Risk: Medium}
\begin{itemize}
    \item Implement the zero-shot and few-shot approaches specified in \textbf{Methodology} with a pre-trained \gls{llm} such as Zephyr-7B-$\beta$.
    \item Evaluate the prompting-based approaches.
\end{itemize}

\textbf{Week 3-4} (29/01-12/02) \hfill \textbf{Risk: Medium}
\begin{itemize}
    \item Construct the dataset and implement the code for fine-tuning. Kick off fine-tuning runs.
    \item While fine-tuning experiments are running, review more literature and re-evaluate the suitability of the current evaluation metric. Implement more evaluation metrics if needed.
\end{itemize}

\textbf{Week 5-6} (12/02-26/02) \hfill \textbf{Risk: Medium}
\begin{itemize}
    \item Evaluate the fine-tuned model.
    \item Review progress so far: Make appropriate changes to the project plan if necessary and plan for extensions.
    \item Continue on developing suitable evaluation metrics, such as by application of the learnt ontology to downstream tasks.
    \item \textbf{Milestone}: Achieved core goals.
\end{itemize}

\textbf{Week 7-8} (26/02-11/03)
\begin{itemize}
    \item Buffer/work on extensions.
    \item Other course work deadlines.
\end{itemize}

\subsubsection*{Easter break}
\textbf{Week 1-2} (11/03-18/03)
\begin{itemize}
    \item Buffer/work on extensions.
\end{itemize}

\textbf{Week 3-4} (18/03-01/04)
\begin{itemize}
    \item Work on extensions.
    \item Begin writing the dissertation: Focus on the introduction and implementation section.
\end{itemize}

\textbf{Week 5-6} (01/04-15/04)
\begin{itemize}
    \item Work on extensions.
    \item \textbf{Milestone}: Completed extensions.
\end{itemize}

\subsubsection*{Easter}
\textbf{Week 1-2} (15/04-29/04) \hfill \textbf{Risk: Low}
\begin{itemize}
    \item Continue writing the dissertation: Complete the remaining core sections (preparation, evaluation).
\end{itemize}

\textbf{Week 3-4} (29/04-13/05) \hfill \textbf{Risk: Low}
\begin{itemize}
    \item Review (and possibly rewrite) some sections of the dissertation.
    \item Complete first draft of dissertation.
    \item \textbf{Milestone}: First draft of dissertation.
\end{itemize}

\textbf{Week 5-6} (13/05-28/05) \hfill \textbf{Risk: Low}
\begin{itemize}
    \item Revise the dissertation based on feedback from the supervisors. Have further discussions about specific issues if necessary.
    \item \textbf{Deadline}: 20/05/2024 Project title deadline.
    \item \textbf{Deadline}: 28/05/2024 Dissertation and source code submission deadline.
    \item \textbf{Milestone}: Submission of dissertation.
\end{itemize}