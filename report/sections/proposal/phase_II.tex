% Main document

\begin{abstract}
    % Write an ``elevator pitch''. In other words what's the
    % problem, why is it important or interesting, and what's your approach. (100 words)
    \noindent Prior to recent progress, \gls{ol} have mostly been tackled with rule-based methods which scale poorly. Recent work by \citet{llms4ol} demonstrated potential for applying \gls{llm} to several subtasks of \gls{ol}. This project aims to extend this idea to build a complete system for \gls{ol} of Wikipedia by leveraging the flexibility of \gls{llm}s, bypassing the needs for manual labour. If successful, this approach, by the virtue of the generality of \gls{llm}s, will be applicable to other corpuses (e.g. other domains/languages) with minimal re-training and modifications.
\end{abstract}

\section*{Introduction, approach and outcomes}

% Provide an introduction to your project or essay. In particular, try to motivate the work and explain the relevant context (general background, as well as sufficient detail about any related work).

% What's the basic idea and approach? What are you thinking of doing, and how is it going to solve the problem (or need) you've identified. What are you going to ``produce''? A project will typically produce one (or perhaps more) of the following: a piece of software, an evaluation of a published result, a proof, or the design (and perhaps the construction of) a new piece of hardware. An essay will typically either review and critique a particular area of the academic literature, or evaluate a published result or proof. Try to name the specific things (and describe them) in this part of the proposal -- this will allow you to refer to them in the next.

\subsection*{What is an Ontology?}

An ontology is a structured representation of widely-accepted concepts. It aims to capture knowledge in a more rigorous form to aid automated processing. A minimal ontology is composed of \emph{classes} and \emph{relations}. Classes are concepts of the ontology. Relations are links that connect two concepts. The basic relation is a \emph{taxonomic relation}, which represent the \emph{is-a}/\emph{subclass-of} relationship. For example, \emph{chatbots} and \emph{artificial intelligence} can be classes of an ontology that are related by a \emph{subclass-of} relation. \gls{ol} is the process of building an ontology in an automatic or semi-automatic way.

In this project, we focus on the categories of Wikipedia which is a simplistic ontology. Other notable examples of ontologies include Gene Ontology \citep{gene-ontology} and Unified Medical Language System \citep{umls}. The standard way to encode ontologies is by \gls{owl} which we will use for the datasets constructed in this project.

\subsection*{Motivation}

\gls{ol} is a complex process. Existing works typically break down the problem into several sub-tasks and employ specialist models to solve each of them individually. On the other hand, \gls{llm}s have been shown to be general problem solvers \citep{gpt3} and encapsulates much world knowledge \citep{llm-knowledge-base}. This makes \gls{llm}s a good candidate for improving the core logic for \gls{ol} while making the process simpler (only one model required).

Most prior work in this area do not evaluate on the complete process of building an ontology from scratch. Instead, they mostly focus on sub-tasks of \gls{ol} or Knowledge Graph Completion \citep{llms4ol,yao2023exploring,cabot2021rebel}. This project will instead build a complete system capable of building ontologies from scratch. We expect to draw inspiration from prior work but also make improvements upon them based on the change in perspective.

\subsection*{Research questions}

The core contribution of this project is to apply \gls{llm}s to build ontology(ies) from scratch. The main question we aim to answer is: \emph{How can we use \gls{llm}s for \gls{ol}?} We plan to do so by:
\begin{enumerate}
    \item Proposing and implementing a system for \gls{ol} where \gls{llm}s plays a central role; and
    \item Demonstrating the effectiveness of the implementation by comparing against existing methods.
\end{enumerate}

Extensions of the project might shed light on:
\begin{itemize}
    \item Can downstream tasks benefit from the resultant ontology?
    \item Can we use \gls{llm}s to discover other components of an ontology?
    \item \emph{How} do \gls{llm}s perform \gls{ol}? For example, do the embeddings/internal activations already form the structure of the ontology?
\end{itemize}

\subsection*{Methodology}

\subsubsection*{Implementation}

The basic implementation of this project will build a minimal ontology in two steps:
\begin{enumerate}
    \item Class discovery: Generate all the `nodes' of the ontology graph. A possible strategy would be to first generate a large set of candidate nodes and classify each of them individually for whether it should be present or not.
    \item Taxonomy discovery: Predict whether a taxonomic relation is present between every pair of nodes. A possible strategy is to iterate through all pairs of nodes and perform a binary classification.
\end{enumerate}

We will employ a pretrained \gls{llm} to solve both sub-tasks by zero-shot prompting (baseline), few-shot prompting, and fine-tuning based on Wikipedia categories. We expect there to be more thoughtful approaches to \gls{ol} than the method described above --- Part of the project's goals is to discover and evaluate such methods.

\subsubsection*{Evaluation}

We will use a hold-out set from Wikipedia categories for in-distribution validation and arXiv categories for out-of-distribution testing.

Standard metrics such as precision and recall will be used to evaluate the system's performance on individual sub-tasks. To evaluate the ontology as a whole, we can compare its similarity with the ground truth. Unfortunately, there is no standard method to compare ontologies though there are vast amounts of literature for reference \citep{ontology-matching}. An alternative method will be to evaluate base on downstream (e.g. document clustering) performance, akin to how typical unsupervised learning methods are evaluated.

To summarise, this project aims to make the following core contributions:
\begin{itemize}
    \item Construct and share a dataset for \gls{ol} based on Wikipedia and arXiv categories.
    \item Be the first to apply \gls{llm}s to build ontologies from scratch and evaluate its end-to-end performance.
\end{itemize}

\section*{Workplan}
% Project students have approximately 26 weeks between the approval of
% the proposal by the Head of Department, and the submission of the dissertation. This section
% should account for what you intend to do during that time. You should divide the time into two-week chunks including dates, and
% describe the work to be done (and, as relevant, milestones to be
% achieved) in each chunk. You should leave two
% chunks for writing a project dissertation. You should leave 1 chunk for contingencies.

\subsection*{Work content}

Core:
\begin{itemize}
    \item Construct the Wikipedia and arXiv categories dataset in \gls{owl} by aggregating data from the public APIs.
    \item Implement a baseline for reference, such as by Named Entity Recognition and Hearst patterns \citep{hearst}.
    \item Propose methods for \gls{ol} using \gls{llm}s, starting with the basic approach described in the previous section. Solve the tasks by zero-shot prompting, few-shot prompting and fine-tuning.
    \item Develop suitable evaluation metrics for computing ontology similarity. Evaluate the resultant ontologies for each method above.
\end{itemize}

Extension:
\begin{itemize}
    \item Apply the learnt ontology for downstream tasks like document clustering and compare the performance against the ground truth and baseline standard (e.g. by embedding similarity).
    \item Use \gls{llm}s to discover additional components of an ontology, such as defining which classes are mutually exclusive.
    \item Inspect the internal activations of \gls{llm}s and probe for structures resembling an ontology. (e.g. is there a direction for "general" vs "specific" concepts?)
\end{itemize}

\subsection*{Success criteria}

We aim to demonstrate the success of the project by:
\begin{enumerate}
    \item Publicly sharing the constructed datasets based on Wikipedia categories and arXiv categories.
    \item Producing higher-quality ontologies than the baseline methods according to our evaluation metrics.
\end{enumerate}

\subsection*{Timeline}

\subsubsection*{Christmas}
\textbf{Week 1-2} \emph{(04/12-18/12)}
\begin{itemize}
    \item Setup access to compute resources (Lab GPUs \& HPC).
    \item Construct the initial Wikipedia \gls{ol} dataset.
    \item Implement prompting-based baselines (following \citet{llms4ol}).
    \item \textbf{Milestone}: Constructed train and evaluation dataset.
\end{itemize}

\textbf{Week 3-4} \emph{(18/12-01/01)}
\begin{itemize}
    \item Run the baseline methods and obtain basic metrics on the sub-tasks (e.g. precision and recall).
    \item Construct the dataset and implement the code for fine-tuning. Run small-scale experiments on the HPC.
    \item \textbf{Milestone}: Established baselines.
\end{itemize}

\textbf{Week 5-6} \emph{(01/01-15/01)}
\begin{itemize}
    \item Reserved time for holiday and other course works.
\end{itemize}

\subsubsection*{Lent}
\textbf{Week 1-2} \emph{(15/01-29/01)}
\begin{itemize}
    \item Full-scale fine-tuning runs.
    \item Construct the test dataset (e.g. from arXiv).
    \item \textbf{Milestone}: Constructed test dataset.
\end{itemize}

\textbf{Week 3-4} \emph{(29/01-12/02)}
\begin{itemize}
    \item Create and develop original evaluation metrics. Might involve application to downstream tasks.
    \item Evaluate the fine-tuned model.
\end{itemize}

\textbf{Week 5-6} \emph{(12/02-26/02)}
\begin{itemize}
    \item Review progress so far: Make appropriate changes to the project plan if necessary and plan for extensions.
    \item Continue on developing suitable evaluation metrics.
    \item \textbf{Milestone}: Achieved core goals.
\end{itemize}

\textbf{Week 7-8} \emph{(26/02-11/03)}
\begin{itemize}
    \item Buffer/work on extensions.
    \item Other course work deadlines.
\end{itemize}

\subsubsection*{Easter break}
\textbf{Week 1-2} \emph{(11/03-18/03)}
\begin{itemize}
    \item Buffer/work on extensions.
\end{itemize}

\textbf{Week 3-4} \emph{(18/03-01/04)}
\begin{itemize}
    \item Work on extensions.
    \item Begin writing the dissertation: Focus on the introduction and implementation section.
    \item \textbf{Milestone}: Achieved extension goals.
\end{itemize}

\textbf{Week 5-6} \emph{(01/04-15/04)}
\begin{itemize}
    \item Work on extensions.
    \item Begin writing the dissertation: Focus on the introduction and implementation section.
    \item \textbf{Milestone}: Achieved extension goals.
\end{itemize}

\subsubsection*{Easter}
\textbf{Week 1-2} \emph{(15/04-29/04)}
\begin{itemize}
    \item Continue writing the dissertation: Complete the remaining core sections (preparation, evaluation).
\end{itemize}

\textbf{Week 3-4} \emph{(29/04-13/05)}
\begin{itemize}
    \item Review (and possibly rewrite) some sections of the dissertation.
    \item Complete first draft of dissertation.
    \item \textbf{Milestone}: First draft of dissertation.
\end{itemize}

\textbf{Week 5-6} \emph{(13/05-28/05)}
\begin{itemize}
    \item Revise the dissertation based on feedback from the supervisors. Have further discussions about specific issues if necessary.
    \item \textbf{Deadline}: 20/05/2024 Project title deadline.
    \item \textbf{Deadline}: 28/05/2024 Dissertation and source code submission deadline.
\end{itemize}